{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26fd0cf6-3c9a-48e2-90b8-45b2a18c4b96",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this jupyter notebook we're filling (removing) MS lesions. We're training a 2D unet model which conditions on a binary mask and the voided image. For training it uses a mixture of random circle masks and lesions masks annotated by doctors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf5d9ef-a296-424d-b975-9e6d5b250c92",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77b51cd-dfaa-44b4-b1f6-a36e07016f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config: \n",
    "    mode = \"train\" # ['train', 'eval']\n",
    "    debug = True\n",
    "    output_dir = \"lesion-filling-256-cond-mixture\" \n",
    "\n",
    "    #dataset config\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\" \n",
    "    target_shape = None # During preprocessing the img gets transformered to this shape (computationally expensive) \n",
    "    unet_img_shape = (256,256) # This defines the input layer of the model\n",
    "    channels = 3 # The number of input channels: 1 for grayscale img, 1 for img_voided, 1 for mask\n",
    "    restrict_train_slices = \"segm\" # Defines which 2D slices are used from the 3D MRI ['mask', 'segm', or 'unrestricted']\n",
    "    restrict_eval_slices = \"mask\" # Defines which 2D slices are used from the 3D MRI ['mask', 'segm', or 'unrestricted']\n",
    "    restrict_mask_to_wm=True # Restricts lesion masks to white matter based on segmentation\n",
    "    proportion_training_circular_masks = 0.5 # Defines if random circular masks should be used instead of the provided lesion masks. \n",
    "                                             # 1 is 100% random circular masks and 0 is 100% lesion masks.\n",
    "    uniform_center_circular_masks = False # the center of the circular mask is uniform within a batch\n",
    "    train_connected_masks=True  # The distribution of the masks is extended by splitting the masks into several smaller connected components.  \t\n",
    "    brightness_augmentation = True\t# The training data gets augmented with randomly applied ColorJitter. \n",
    "    num_dataloader_workers = 8 # how many subprocesses to use for data loading\n",
    "\n",
    "    # train config \n",
    "    num_epochs = 115 \n",
    "    sorted_slice_sample_size = 1 # The number of sorted slices within one sample. Defaults to 1.\n",
    "                                 # This is needed for the pseudo3Dmodels, where the model expects that the slices within one batch\n",
    "                                 # are next to each other in the 3D volume.\n",
    "    train_batch_size = None\n",
    "    effective_train_batch_size=32  # The train_batch_size gets recalculated to this batch size based on accumulation_steps and number of GPU's.\n",
    "\t                                # For pseudo3D models the sorted_slice_sample_size gets calculcated to this batch size. \n",
    "                                    # The train_batch_size and eval_batch_size should be 1.\n",
    "    eval_batch_size = 16 \n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500 \n",
    "    use_min_snr_loss=False\n",
    "    snr_gamma=5\n",
    "    gradient_accumulation_steps = 1\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision \n",
    "\n",
    "    # evaluation config\n",
    "    num_inference_steps=50\n",
    "    evaluate_2D_epochs = 3 # The interval at which to evaluate the model on 2D images. \n",
    "    evaluate_3D_epochs = 1000  # The interval at which to evaluate the model on 3D images.  \n",
    "    evaluate_num_batches = 20 # Number of batches used for evaluation. -1 means all batches. \n",
    "    evaluate_num_batches_3d = 2 # Number of batches used for evaluation. -1 means all batches. \n",
    "    evaluate_unconditional_img = False # Used for unconditional models to generate some samples without the repaint pipeline. \n",
    "    deactivate_2D_evaluation = False\n",
    "    deactivate_3D_evaluation = True\n",
    "    img3D_filename = \"T1\" # Filename to save the processed 3D images \n",
    "    eval_loss_timesteps=[20,80,140,200,260,320,380,440,560,620,680,740,800,860,920,980] # List of timesteps to evalute validation loss.\n",
    "    eval_mask_dilation = 0 # dilation value for masks\n",
    "    #add_lesion_technique = \"other_lesions_99Quantile\" # Used for synthesis only. \n",
    "                                                      # ['empty', 'mean_intensity', 'other_lesions_1stQuantile', 'other_lesions_mean', \n",
    "                                                      # 'other_lesions_median', 'other_lesions_3rdQuantile', 'other_lesions_99Quantile'] \n",
    "    #intermediate_timestep = 3 # Used for synthesis only. Diffusion process starts from this timesteps. \n",
    "                               # Num_inference_steps means the whole pipeline and 1 the last step. \n",
    "    #jump_length = 8 # Used for unconditional lesion filling only. Defines the jump_length from the repaint paper.\n",
    "    #jump_n_sample = 10 # Used for unconditional lesion filling only. Defines the jump_n_sample from the repaint paper.\n",
    "    log_csv = False # saves evaluation metrics as csv \n",
    "    seed = 0 # used for dataloader sampling and generation of the initial noise to start the diffusion process\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e2ffca-7e8c-43d4-8e13-ba1900e38eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d98a516-6f3c-4d6e-8df8-2597ef20846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "with open(Path.home() / \".cache/huggingface/accelerate/default_config.yaml\") as f:\n",
    "    data = json.load(f)\n",
    "    config.num_processes = data[\"num_processes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4e3e6f-f59e-4844-a908-b21feae83211",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_batch_size = int((config.effective_train_batch_size / config.gradient_accumulation_steps) / config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37af310-fb03-4445-a931-bc7e4f359ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.eval_loss_timesteps = [20]\n",
    "    config.train_connected_masks=False\n",
    "    config.eval_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\"\n",
    "    config.num_dataloader_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f849e8-b970-435d-aa9e-a6b04c061f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with batch size 1, 1 accumulation steps and 1 process(es)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Start training with batch size {config.train_batch_size}, {config.gradient_accumulation_steps} accumulation steps and {config.num_processes} process(es)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a78a6-a74c-4366-a7a1-1a704880687f",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-24 11:07:44.012774: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 11:07:44.705527: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-24 11:07:44.705572: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-24 11:07:44.709636: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-24 11:07:45.148418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-24 11:07:45.152209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-24 11:07:48.915584: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208fa89923c1432caed8c00bc11e7782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04ddca3742d429fab1d0afa40144e5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f26d449282149fda309c6aa077ff9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "from pathlib import Path\n",
    "from torchvision import transforms \n",
    " \n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    " \n",
    "dataset_train = DatasetMRI2D(\n",
    "    root_dir_img=Path(config.dataset_train_path), \n",
    "    root_dir_masks=Path(config.masks_train_path),\n",
    "    root_dir_segm=Path(config.segm_train_path),  \n",
    "    restriction=config.restrict_train_slices, \n",
    "    proportion_training_circular_masks=config.proportion_training_circular_masks,\n",
    "    circle_mask_shape=config.unet_img_shape, \n",
    "    uniform_mask_center=config.uniform_center_circular_masks,\n",
    "    default_to_circular_mask=True,\n",
    "    connected_masks=config.train_connected_masks, \n",
    "    restrict_mask_to_wm=config.restrict_mask_to_wm, \n",
    "    transforms=transformations, \n",
    "    sorted_slice_sample_size=config.sorted_slice_sample_size, \n",
    "    target_shape=config.target_shape, \n",
    ")\n",
    "dataset_evaluation = DatasetMRI2D(\n",
    "    root_dir_img=Path(config.dataset_eval_path), \n",
    "    root_dir_masks=Path(config.masks_eval_path), \n",
    "    restriction=config.restrict_eval_slices, \n",
    "    dilation=config.eval_mask_dilation,\n",
    "    sorted_slice_sample_size=config.sorted_slice_sample_size, \n",
    "    target_shape=config.target_shape, \n",
    ")\n",
    "dataset_3D_evaluation = DatasetMRI3D(\n",
    "    root_dir_img=Path(config.dataset_eval_path), \n",
    "    root_dir_masks=Path(config.masks_eval_path),\n",
    "    dilation=config.eval_mask_dilation,\n",
    "    target_shape=config.target_shape, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3337e974-6e0c-48b6-a2ba-c301824ba029",
   "metadata": {},
   "source": [
    "### Training environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7509adcf-a0b1-4652-a5ca-b398b008dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  \n",
    "    in_channels=config.channels,  \n",
    "    out_channels=1,   \n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  \n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",   \n",
    "        \"AttnDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpBlock2D\",  \n",
    "        \"AttnUpBlock2D\",   \n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"BigUNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05f67f7-b932-4f73-bdb3-96751ef6c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "#setup noise scheduler\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000) \n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5171c3aa-3a69-4dfa-bbb2-d3c8086fb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "# setup lr scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(dataset_train)/config.train_batch_size) * config.num_epochs),  \n",
    ")\n",
    "\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e750167b-e2ba-4132-b46d-0a109506c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator \n",
    "\n",
    "# setup accelerator for distributed training\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=config.mixed_precision,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f31ff4-2d41-43f9-93a9-6888fd19618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from custom_modules import Logger\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    if config.output_dir is not None:\n",
    "        os.makedirs(config.output_dir, exist_ok=True) \n",
    "    #setup tensorboard\n",
    "    tb_summary = SummaryWriter(config.output_dir, purge_step=0)\n",
    "    accelerator.init_trackers(\"train_example\") #maybe delete\n",
    "    logger = Logger(tb_summary, config.log_csv)\n",
    "    logger.log_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e0845c8-029c-4cab-b90c-be9cb5478add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import get_dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(\n",
    "    dataset=dataset_train, \n",
    "    batch_size=config.train_batch_size, \n",
    "    num_workers=config.num_dataloader_workers, \n",
    "    random_sampler=True, \n",
    "    seed=config.seed, \n",
    "    multi_slice=config.sorted_slice_sample_size > 1\n",
    ")\n",
    "d2_eval_dataloader = get_dataloader(\n",
    "    dataset=dataset_evaluation, \n",
    "    batch_size=config.eval_batch_size, \n",
    "    num_workers=config.num_dataloader_workers, \n",
    "    random_sampler=False, seed=config.seed, \n",
    "    multi_slice=config.sorted_slice_sample_size > 1\n",
    ")\n",
    "d3_eval_dataloader = get_dataloader(\n",
    "    dataset=dataset_3D_evaluation, \n",
    "    batch_size=1, \n",
    "    num_workers=config.num_dataloader_workers,\n",
    "    random_sampler=False, \n",
    "    seed=config.seed, \n",
    "    multi_slice=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa1d9612-7c96-4c4f-b4ee-cd81d3a956cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, d2_eval_dataloader, d3_eval_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, d2_eval_dataloader, d3_eval_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aadc65be-ba62-454f-a449-fd7c10709609",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /home/jovyan/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno 99] Cannot assign requested address>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:1348\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1348\u001b[0m     \u001b[43mh\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1349\u001b[0m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTransfer-encoding\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1350\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1286\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1286\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1332\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1331\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1332\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1281\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1281\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1041\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1041\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m \n\u001b[1;32m   1045\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:979\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m--> 979\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:1451\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1451\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/http/client.py:945\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    944\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[0;32m--> 945\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:851\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m all_errors:\n\u001b[0;32m--> 851\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    852\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ExceptionGroup(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreate_connection failed\u001b[39m\u001b[38;5;124m\"\u001b[39m, exceptions)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/socket.py:836\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[1;32m    835\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m--> 836\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 99] Cannot assign requested address",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m      3\u001b[0m model_input_generator \u001b[38;5;241m=\u001b[39m ModelInputGenerator(conditional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, noise_scheduler\u001b[38;5;241m=\u001b[39mnoise_scheduler)\n\u001b[1;32m      5\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: d2_eval_dataloader, \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_dataloader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mseed\n\u001b[1;32m     16\u001b[0m }\n\u001b[0;32m---> 17\u001b[0m evaluation2D \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluation2DFilling\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: d3_eval_dataloader, \n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m accelerator\u001b[38;5;241m.\u001b[39mis_main_process \u001b[38;5;28;01melse\u001b[39;00m logger, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mseed,\n\u001b[1;32m     29\u001b[0m }\n\u001b[1;32m     30\u001b[0m evaluation3D \u001b[38;5;241m=\u001b[39m Evaluation3DFilling(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/Evaluation2DFilling.py:30\u001b[0m, in \u001b[0;36mEvaluation2DFilling.__init__\u001b[0;34m(self, eval_dataloader, train_dataloader, logger, accelerator, num_inference_steps, model_input_generator, output_dir, eval_loss_timesteps, evaluate_num_batches, seed)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, eval_dataloader: DataLoader, train_dataloader: DataLoader, \n\u001b[1;32m     27\u001b[0m              logger: Logger, accelerator: Accelerator, num_inference_steps: \u001b[38;5;28mint\u001b[39m, \n\u001b[1;32m     28\u001b[0m              model_input_generator: ModelInputGenerator, output_dir: \u001b[38;5;28mstr\u001b[39m, eval_loss_timesteps: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mint\u001b[39m], \n\u001b[1;32m     29\u001b[0m              evaluate_num_batches: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, seed: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 30\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_inference_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                     \u001b[49m\u001b[43meval_loss_timesteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_num_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/Evaluation2D.py:56\u001b[0m, in \u001b[0;36mEvaluation2D.__init__\u001b[0;34m(self, eval_dataloader, train_dataloader, logger, accelerator, num_inference_steps, model_input_generator, output_dir, eval_loss_timesteps, evaluate_num_batches, seed)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_num_batches \u001b[38;5;241m=\u001b[39m evaluate_num_batches\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;241m=\u001b[39m seed\n\u001b[0;32m---> 56\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlpips_metric \u001b[38;5;241m=\u001b[39m \u001b[43mLearnedPerceptualImagePatchSimilarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchmetrics/image/lpip.py:124\u001b[0m, in \u001b[0;36mLearnedPerceptualImagePatchSimilarity.__init__\u001b[0;34m(self, net_type, reduction, normalize, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m net_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_net_type:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `net_type` must be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_net_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnet_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 124\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[43m_NoTrainLpips\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnet_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m valid_reduction \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduction \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_reduction:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchmetrics/functional/image/lpips.py:305\u001b[0m, in \u001b[0;36m_LPIPS.__init__\u001b[0;34m(self, pretrained, net, spatial, pnet_rand, pnet_tune, use_dropout, model_path, eval_mode, resize)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m384\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m]\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchns)\n\u001b[0;32m--> 305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnet \u001b[38;5;241m=\u001b[39m \u001b[43mnet_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpnet_rand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpnet_tune\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin0 \u001b[38;5;241m=\u001b[39m NetLinLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchns[\u001b[38;5;241m0\u001b[39m], use_dropout\u001b[38;5;241m=\u001b[39muse_dropout)\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1 \u001b[38;5;241m=\u001b[39m NetLinLayer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchns[\u001b[38;5;241m1\u001b[39m], use_dropout\u001b[38;5;241m=\u001b[39muse_dropout)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchmetrics/functional/image/lpips.py:110\u001b[0m, in \u001b[0;36mAlexnet.__init__\u001b[0;34m(self, requires_grad, pretrained)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, requires_grad: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, pretrained: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m--> 110\u001b[0m     alexnet_pretrained_features \u001b[38;5;241m=\u001b[39m \u001b[43m_get_net\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malexnet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice1 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchmetrics/functional/image/lpips.py:57\u001b[0m, in \u001b[0;36m_get_net\u001b[0;34m(net, pretrained)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TORCHVISION_GREATER_EQUAL_0_13:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pretrained:\n\u001b[0;32m---> 57\u001b[0m         pretrained_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_weight_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIMAGENET1K_V1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mfeatures\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         pretrained_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(tv, net)(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\u001b[38;5;241m.\u001b[39mfeatures\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:142\u001b[0m, in \u001b[0;36mkwonly_to_pos_or_kw.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    136\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msequence_to_str(\u001b[38;5;28mtuple\u001b[39m(keyword_only_kwargs\u001b[38;5;241m.\u001b[39mkeys()),\u001b[38;5;250m \u001b[39mseparate_last\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mand \u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m as positional \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    137\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    139\u001b[0m     )\n\u001b[1;32m    140\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(keyword_only_kwargs)\n\u001b[0;32m--> 142\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/models/_utils.py:228\u001b[0m, in \u001b[0;36mhandle_legacy_interface.<locals>.outer_wrapper.<locals>.inner_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kwargs[pretrained_param]\n\u001b[1;32m    226\u001b[0m     kwargs[weights_param] \u001b[38;5;241m=\u001b[39m default_weights_arg\n\u001b[0;32m--> 228\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbuilder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/models/alexnet.py:117\u001b[0m, in \u001b[0;36malexnet\u001b[0;34m(weights, progress, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m model \u001b[38;5;241m=\u001b[39m AlexNet(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torchvision/models/_api.py:90\u001b[0m, in \u001b[0;36mWeightsEnum.get_state_dict\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_state_dict\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mload_state_dict_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/hub.py:766\u001b[0m, in \u001b[0;36mload_state_dict_from_url\u001b[0;34m(url, model_dir, map_location, progress, check_hash, file_name, weights_only)\u001b[0m\n\u001b[1;32m    764\u001b[0m         r \u001b[38;5;241m=\u001b[39m HASH_REGEX\u001b[38;5;241m.\u001b[39msearch(filename)  \u001b[38;5;66;03m# r is Optional[Match[str]]\u001b[39;00m\n\u001b[1;32m    765\u001b[0m         hash_prefix \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m r \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 766\u001b[0m     \u001b[43mdownload_url_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhash_prefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_legacy_zip_format(cached_file):\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _legacy_zip_load(cached_file, model_dir, map_location, weights_only)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/hub.py:620\u001b[0m, in \u001b[0;36mdownload_url_to_file\u001b[0;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[1;32m    618\u001b[0m file_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    619\u001b[0m req \u001b[38;5;241m=\u001b[39m Request(url, headers\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.hub\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[0;32m--> 620\u001b[0m u \u001b[38;5;241m=\u001b[39m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    621\u001b[0m meta \u001b[38;5;241m=\u001b[39m u\u001b[38;5;241m.\u001b[39minfo()\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(meta, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetheaders\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:519\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    516\u001b[0m     req \u001b[38;5;241m=\u001b[39m meth(req)\n\u001b[1;32m    518\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[0;32m--> 519\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[1;32m    522\u001b[0m meth_name \u001b[38;5;241m=\u001b[39m protocol\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_response\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:536\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[0;34m(self, req, data)\u001b[0m\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    535\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[0;32m--> 536\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\n\u001b[1;32m    537\u001b[0m \u001b[43m                          \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_open\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[1;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[0;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:1391\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m   1390\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[0;32m-> 1391\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/urllib/request.py:1351\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[0;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[1;32m   1349\u001b[0m                   encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m   1350\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[1;32m   1352\u001b[0m     r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m   1353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error [Errno 99] Cannot assign requested address>"
     ]
    }
   ],
   "source": [
    "from custom_modules import ModelInputGenerator, Evaluation2DFilling, Evaluation3DFilling \n",
    "\n",
    "model_input_generator = ModelInputGenerator(conditional=True, noise_scheduler=noise_scheduler)\n",
    " \n",
    "args = {\n",
    "    \"eval_dataloader\": d2_eval_dataloader, \n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"eval_loss_timesteps\": config.eval_loss_timesteps, \n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches, \n",
    "    \"seed\": config.seed\n",
    "}\n",
    "evaluation2D = Evaluation2DFilling(**args)\n",
    "args = {\n",
    "    \"dataloader\": d3_eval_dataloader, \n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"filename\": config.img3D_filename,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"eval_batch_size\": config.eval_batch_size,\n",
    "    \"sorted_slice_sample_size\": config.sorted_slice_sample_size,\n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches_3d,\n",
    "    \"seed\": config.seed,\n",
    "}\n",
    "evaluation3D = Evaluation3DFilling(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd27c9b-e128-437d-b003-555d9a6ddd25",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff9863-09e9-4951-a6d3-323cd9a15a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import Training, DDIMInpaintPipeline, Evaluation2DFilling, Evaluation3DFilling\n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "args = { \n",
    "    \"accelerator\": accelerator,\n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"train_dataloader\": train_dataloader, \n",
    "    \"d2_eval_dataloader\": d2_eval_dataloader, \n",
    "    \"d3_eval_dataloader\": d3_eval_dataloader, \n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"evaluation2D\": evaluation2D,\n",
    "    \"evaluation3D\": evaluation3D,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger,\n",
    "    \"pipeline_factory\": PipelineFactories.get_ddim_inpaint_pipeline,\n",
    "    \"num_epochs\": config.num_epochs, \n",
    "    \"evaluate_2D_epochs\": config.evaluate_2D_epochs,\n",
    "    \"evaluate_3D_epochs\": config.evaluate_3D_epochs,\n",
    "    \"min_snr_loss\": config.use_min_snr_loss,\n",
    "    \"snr_gamma\": config.snr_gamma,\n",
    "    \"evaluate_unconditional_img\": config.evaluate_unconditional_img,\n",
    "    \"deactivate_2D_evaluation\": config.deactivate_2D_evaluation, \n",
    "    \"deactivate_3D_evaluation\": config.deactivate_3D_evaluation, \n",
    "    \"evaluation_pipeline_parameters\": {},\n",
    "    \"debug\": config.debug, \n",
    "    }\n",
    "trainingMixture = Training(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba08bca-fc1f-431d-85ba-733f2a6f73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"train\":\n",
    "    trainingMixture.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f04c0c-2be6-4683-aae7-0bde77668354",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    trainingMixture.deactivate_3D_evaluation = False\n",
    "    pipeline = DDIMInpaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingMixture.evaluate(pipeline, deactivate_save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57c0c6-43be-4c06-90bc-3e50b56a8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89139d7-4a1d-4616-9059-09c16e85b5b4",
   "metadata": {},
   "source": [
    "### Save jupyter notebook as python script for hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fb612-dede-46d9-abd1-ed1cc23b01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script \"lesion_filling_conditioned_mixture.ipynb\"\n",
    "filename=\"lesion_filling_conditioned_mixture.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-18: \n",
    "            fp.write(line) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
