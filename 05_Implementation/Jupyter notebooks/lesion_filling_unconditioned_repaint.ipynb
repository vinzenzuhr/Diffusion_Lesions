{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b277e45-ea4c-4639-9398-d22356d0222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './custom_modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1e0a8-8f60-4b1b-94b8-8367832dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    image_size = 256  # TODO: the generated image resolution\n",
    "    image_shape = (256,256,160)\n",
    "    channels = 1\n",
    "    train_batch_size = 4 \n",
    "    eval_batch_size = 4  \n",
    "    num_epochs = 350\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    evaluate_epochs = 40 # anpassen auf Anzahl epochs\n",
    "    evaluate_num_batches = 2 # one batch needs ~130s \n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_3D_epochs = 1000  # one 3D evaluation has 77 slices and needs 166min\n",
    "    save_model_epochs = 300\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-filling-256-repaint\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\"  \n",
    "    train_only_connected_masks=False  # No Training with lesion masks\n",
    "    eval_only_connected_masks=False \n",
    "    num_inference_steps=50\n",
    "    mode = \"eval\" # train / eval\n",
    "    debug = True\n",
    "    jump_length=8\n",
    "    jump_n_sample=10 \n",
    "    #uniform_dataset_path = \"./uniform_dataset\"\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    #hub_model_id = \"<your-username>/<my-awesome-model>\"  # the name of the repository to create on the HF Hub\n",
    "    #hub_private_repo = False\n",
    "    #overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc472c2-c374-4859-8ed5-791ebeafbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.train_only_connected_masks=False\n",
    "    config.eval_only_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    dataset_train_path = \"./dataset_eval/imgs\"\n",
    "    segm_train_path = \"./dataset_eval/segm\"\n",
    "    masks_train_path = \"./dataset_eval/masks\"  \n",
    "    config.jump_length=1\n",
    "    config.jump_n_sample=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521352b5-cf3f-41a2-b9c3-2fbf8c07c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee1280d7bfe42ccb1d34f5f22815e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bd626ecbb547cea97793fe522cf0e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1b571ca72f4dd496c17c4f56c18467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from DatasetMRI2D import DatasetMRI2D\n",
    "from DatasetMRI3D import DatasetMRI3D\n",
    "from pathlib import Path\n",
    "\n",
    "#create dataset\n",
    "datasetTrain = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), root_dir_segm=Path(config.segm_train_path), only_connected_masks=config.train_only_connected_masks)\n",
    "datasetEvaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks)\n",
    "dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1188218d-a16d-4c0a-896f-e47a140bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.image_size,  # the target image resolution\n",
    "    in_channels=config.channels,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"UNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a40c63-4ba1-44aa-8c62-7f15ce816225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f42d0a-9ebb-4437-b180-12b79af3c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(datasetTrain)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ff284a-4306-4677-829e-98fef153fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-08 16:31:35.253583: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-08 16:31:35.331058: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-08 16:31:35.331161: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-08 16:31:35.331201: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-08 16:31:35.358784: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-04-08 16:31:35.361915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-08 16:31:39.227963: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from TrainingUnconditional import TrainingUnconditional\n",
    "from RePaintPipeline import RePaintPipeline\n",
    "from Evaluation2DFilling import Evaluation2DFilling\n",
    "from Evaluation3DFilling import Evaluation3DFilling \n",
    "import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bac4e0a-2837-4217-a97c-ce940bdc2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"train\":\n",
    "    args = {\n",
    "        \"config\": config, \n",
    "        \"model\": model, \n",
    "        \"noise_scheduler\": noise_scheduler, \n",
    "        \"optimizer\": optimizer, \n",
    "        \"lr_scheduler\": lr_scheduler, \n",
    "        \"datasetTrain\": datasetTrain, \n",
    "        \"datasetEvaluation\": datasetEvaluation, \n",
    "        \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "        \"evaluation2D\": Evaluation2DFilling,\n",
    "        \"evaluation3D\": Evaluation3DFilling, \n",
    "        \"pipelineFactory\": PipelineFactories.get_repaint_pipeline,\n",
    "        \"deactivate3Devaluation\": config.deactivate3Devaluation,\n",
    "        \"evaluation_pipeline_parameters\": {\n",
    "                    \"jump_length\": config.jump_length,\n",
    "                    \"jump_n_sample\": config.jump_n_sample,\n",
    "                }} \n",
    "    \n",
    "    trainingRepaint = TrainingUnconditional(**args)\n",
    "    trainingRepaint.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8be7971-c0ac-461d-9fcf-78481e7c9158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17201ceb7614d0882a219f7a9077344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/./custom_modules/RePaintPipeline.py:32: FutureWarning: The preprocess method is deprecated and will be removed in diffusers 1.0.0. Please use VaeImageProcessor.preprocess(...) instead\n",
      "  deprecate(\"preprocess\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d57446dcf9e0455fb3f4dcf3dc2a33af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssim_full: 0.9578241109848022\n",
      "ssim_out: 0.9735791683197021\n",
      "ssim_in: 0.02977410890161991\n",
      "mse_full: 0.011394891887903214\n",
      "mse_out: nan\n",
      "mse_in: 0.682610273361206\n",
      "psnr_full: 25.45349884033203\n",
      "psnr_out: nan\n",
      "psnr_in: 7.6788716316223145\n",
      "val_loss: 0.2266809344291687\n",
      "lpips: 0.49181067943573\n",
      "global_step:  0\n",
      "image saved\n",
      "Start 3D evaluation\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa52e903ae4242e0afb8fe0594336d72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b9480cb2a4244439b4808ee277b409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5df153b5da487488500ea154860305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2268fef966c4414a8621a7ccd8ba8f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bbdf32ce8574c07a1ab6c49bb203194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e84aa92bb94edca7251cfcea715b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe6f5040b4054478b0c863e1c6c9c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f511dd974c40c389b9b963a28d3f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b39e74fdcca4995ae5015c402127269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21dd6a2353364d23a99a895a26f8dcfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "687531fa49864f5ab44426ccd7f9f10b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92178755886b4e048fac672ef49708fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b216d765df40cab3fd84f21b9b239d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3152b1f86057421f9604c6bf689e38ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ccb39fb43014e2682af4096abfe28af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bc35294dd24c96aa6d27e90f5c813c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7b0486c2d3a4335ac1616f45e583be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if config.mode == \"eval\": # Nr. 17 has around ~80 2D slides with mask content\n",
    "    config.deactivate3Devaluation = False\n",
    "    args = {\n",
    "        \"config\": config, \n",
    "        \"model\": model, \n",
    "        \"noise_scheduler\": noise_scheduler, \n",
    "        \"optimizer\": optimizer, \n",
    "        \"lr_scheduler\": lr_scheduler, \n",
    "        \"datasetTrain\": datasetTrain, \n",
    "        \"datasetEvaluation\": datasetEvaluation, \n",
    "        \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "        \"evaluation2D\": Evaluation2DFilling,\n",
    "        \"evaluation3D\": Evaluation3DFilling, \n",
    "        \"pipelineFactory\": PipelineFactories.get_repaint_pipeline, \n",
    "        \"deactivate3Devaluation\": config.deactivate3Devaluation,\n",
    "        \"evaluation_pipeline_parameters\": {\n",
    "                    \"jump_length\": config.jump_length,\n",
    "                    \"jump_n_sample\": config.jump_n_sample,\n",
    "                }} \n",
    "    \n",
    "    trainingRepaint = TrainingUnconditional(**args)\n",
    "    pipeline = RePaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingRepaint.evaluate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e5c59-4c1c-4fc9-8ffc-4fddca8e2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be170a32-fcb6-41b1-b6ea-14b77eb7b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create python script for ubelix \n",
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"lesion_filling_unconditioned_repaint.ipynb\"\n",
    "filename=\"lesion_filling_unconditioned_repaint.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
