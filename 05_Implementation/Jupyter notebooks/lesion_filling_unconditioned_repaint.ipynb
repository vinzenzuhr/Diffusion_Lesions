{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1e0a8-8f60-4b1b-94b8-8367832dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:  \n",
    "    t1n_target_shape = None # will transform t1n during preprocessing (computationally expensive)\n",
    "    unet_img_shape = (256,256)\n",
    "    channels = 1\n",
    "    effective_train_batch_size=32 \n",
    "    eval_batch_size = 16  \n",
    "    num_sorted_samples = 1\n",
    "    num_dataloader_workers = 8\n",
    "    evaluate_num_batches = 4 # one batch needs ~130s \n",
    "    num_epochs = 1500\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    evaluate_epochs = 40 # anpassen auf Anzahl epochs\n",
    "    deactivate2Devaluation = False\n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_3D_epochs = 1000  # one 3D evaluation has 77 slices and needs 166min\n",
    "    evaluate_num_batches_3d = -1  \n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-filling-256-repaint\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\"  \n",
    "    train_only_connected_masks=False  # No Training with lesion masks\n",
    "    eval_only_connected_masks=False \n",
    "    num_inference_steps=50 \n",
    "    log_csv = False\n",
    "    mode = \"eval\" # train / eval\n",
    "    debug = True\n",
    "    jump_length=8\n",
    "    jump_n_sample=10 \n",
    "    brightness_augmentation = True\n",
    "    eval_mask_dilation=1\n",
    "    #uniform_dataset_path = \"./uniform_dataset\"\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    #hub_model_id = \"<your-username>/<my-awesome-model>\"  # the name of the repository to create on the HF Hub\n",
    "    #hub_private_repo = False\n",
    "    #overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "    eval_loss_timesteps= [20,80,140,200,260,320,380,440,560,620,680,740,800,860,920,980] #[20,40,80,140]\n",
    "    restrict_train_slices = \"segm\"\n",
    "    restrict_eval_slices = \"mask\"\n",
    "    use_min_snr_loss=True\n",
    "    snr_gamma=5\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a18cf94-6408-41f3-b192-27f5804d0b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a7c285a-9e8e-4cb3-aeb9-33618b7ca7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "with open(Path.home() / \".cache/huggingface/accelerate/default_config.yaml\") as f:\n",
    "    data = json.load(f)\n",
    "    config.num_processes = data[\"num_processes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe394c0-6405-466c-9aa7-4a6df5386968",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_batch_size = int((config.effective_train_batch_size / config.gradient_accumulation_steps) / config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc472c2-c374-4859-8ed5-791ebeafbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.eval_loss_timesteps = [20]\n",
    "    config.train_only_connected_masks=False\n",
    "    config.eval_only_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\"\n",
    "    config.jump_length=1\n",
    "    config.jump_n_sample=1\n",
    "    config.num_dataloader_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7874eff6-0723-4072-a3a5-7103760ff901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with batch size 8, 2 accumulation steps and 1 process(es)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Start training with batch size {config.train_batch_size}, {config.gradient_accumulation_steps} accumulation steps and {config.num_processes} process(es)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c972b9bfac4f238bace669dca5ebac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "\n",
    "#add augmentation\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5) \n",
    "\n",
    "#create dataset\n",
    "datasetTrain = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), restriction=config.restrict_train_slices, root_dir_segm=Path(config.segm_train_path), only_connected_masks=config.train_only_connected_masks, t1n_target_shape=config.t1n_target_shape, transforms=transformations)\n",
    "datasetEvaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), restriction=config.restrict_eval_slices, root_dir_masks=Path(config.masks_eval_path), root_dir_segm=Path(config.segm_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape, dilation=config.eval_mask_dilation)\n",
    "dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), root_dir_segm=Path(config.segm_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape, dilation=config.eval_mask_dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1188218d-a16d-4c0a-896f-e47a140bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=config.channels,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"UNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a40c63-4ba1-44aa-8c62-7f15ce816225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4f42d0a-9ebb-4437-b180-12b79af3c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(datasetTrain)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2ff284a-4306-4677-829e-98fef153fb7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TrainingConfig' object has no attribute 'num_dataloader_worker'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m      4\u001b[0m config\u001b[38;5;241m.\u001b[39mconditional_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m\"\u001b[39m: config, \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjump_n_sample\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mjump_n_sample,\n\u001b[1;32m     22\u001b[0m             }} \n\u001b[0;32m---> 24\u001b[0m trainingRepaint \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingUnconditional\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/TrainingUnconditional.py:8\u001b[0m, in \u001b[0;36mTrainingUnconditional.__init__\u001b[0;34m(self, config, model, noise_scheduler, optimizer, lr_scheduler, datasetTrain, datasetEvaluation, dataset3DEvaluation, evaluation2D, evaluation3D, pipelineFactory, multi_sample, deactivate3Devaluation, evaluation_pipeline_parameters)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, model, noise_scheduler, optimizer, lr_scheduler, datasetTrain, datasetEvaluation, dataset3DEvaluation, evaluation2D, evaluation3D, pipelineFactory, multi_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, deactivate3Devaluation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, evaluation_pipeline_parameters \u001b[38;5;241m=\u001b[39m {}):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasetTrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatasetEvaluation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset3DEvaluation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation2D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluation3D\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipelineFactory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmulti_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdeactivate3Devaluation \u001b[38;5;241m=\u001b[39m deactivate3Devaluation\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_pipeline_parameters \u001b[38;5;241m=\u001b[39m evaluation_pipeline_parameters\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/Training.py:49\u001b[0m, in \u001b[0;36mTraining.__init__\u001b[0;34m(self, config, model, noise_scheduler, optimizer, lr_scheduler, datasetTrain, datasetEvaluation, dataset3DEvaluation, evaluation2D, evaluation3D, pipelineFactory, multi_sample)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator \u001b[38;5;241m=\u001b[39m Accelerator(\n\u001b[1;32m     42\u001b[0m     mixed_precision\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmixed_precision,\n\u001b[1;32m     43\u001b[0m     gradient_accumulation_steps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps, \n\u001b[1;32m     44\u001b[0m     project_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(config\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;66;03m#evt. delete\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m#kwargs_handlers=[InitProcessGroupKwargs(timeout=timedelta(seconds=2 * 1800))],\u001b[39;00m\n\u001b[1;32m     46\u001b[0m ) \n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader \u001b[38;5;241m=\u001b[39m get_dataloader(dataset \u001b[38;5;241m=\u001b[39m datasetTrain, batch_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtrain_batch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_dataloader_workers ,random_sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed, multi_sample\u001b[38;5;241m=\u001b[39mmulti_sample)\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md2_eval_dataloader \u001b[38;5;241m=\u001b[39m get_dataloader(dataset \u001b[38;5;241m=\u001b[39m datasetEvaluation, batch_size \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39meval_batch_size, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_dataloader_worker\u001b[49m, random_sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed, multi_sample\u001b[38;5;241m=\u001b[39mmulti_sample)\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md3_eval_dataloader \u001b[38;5;241m=\u001b[39m get_dataloader(dataset \u001b[38;5;241m=\u001b[39m dataset3DEvaluation, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_dataloader_worker, random_sampler\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed, multi_sample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)        \n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mis_main_process:\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;66;03m#setup tensorboard\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'TrainingConfig' object has no attribute 'num_dataloader_worker'"
     ]
    }
   ],
   "source": [
    "from custom_modules import TrainingUnconditional, RePaintPipeline, Evaluation2DFilling, Evaluation3DFilling \n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"None\"\n",
    "\n",
    "args = {\n",
    "    \"config\": config, \n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"datasetTrain\": datasetTrain, \n",
    "    \"datasetEvaluation\": datasetEvaluation, \n",
    "    \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "    \"evaluation2D\": Evaluation2DFilling,\n",
    "    \"evaluation3D\": Evaluation3DFilling,\n",
    "    \"pipelineFactory\": PipelineFactories.get_repaint_pipeline,\n",
    "    \"min_snr_loss\":config.use_min_snr_loss,\n",
    "    \"deactivate3Devaluation\": config.deactivate3Devaluation,\n",
    "    \"evaluation_pipeline_parameters\": {\n",
    "                \"jump_length\": config.jump_length,\n",
    "                \"jump_n_sample\": config.jump_n_sample,\n",
    "            }} \n",
    "\n",
    "trainingRepaint = TrainingUnconditional(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac4e0a-2837-4217-a97c-ce940bdc2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"train\": \n",
    "    trainingRepaint.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be7971-c0ac-461d-9fcf-78481e7c9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\": # Nr. 17 has around ~80 2D slides with mask content\n",
    "    trainingRepaint.config.deactivate3Devaluation = False \n",
    "    pipeline = RePaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingRepaint.evaluate(pipeline, deactivate_save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e5c59-4c1c-4fc9-8ffc-4fddca8e2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be170a32-fcb6-41b1-b6ea-14b77eb7b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lesion_filling_unconditioned_repaint.ipynb to script\n",
      "[NbConvertApp] Writing 8489 bytes to lesion_filling_unconditioned_repaint.py\n"
     ]
    }
   ],
   "source": [
    "#create python script for ubelix \n",
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"lesion_filling_unconditioned_repaint.ipynb\"\n",
    "filename=\"lesion_filling_unconditioned_repaint.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
