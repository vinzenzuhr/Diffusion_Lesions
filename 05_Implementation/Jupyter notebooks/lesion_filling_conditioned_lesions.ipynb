{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77b51cd-dfaa-44b4-b1f6-a36e07016f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig: \n",
    "    t1n_target_shape = None # will transform t1n during preprocessing (computationally expensive)\n",
    "    unet_img_shape = (256,256)\n",
    "    channels = 1 \n",
    "    train_batch_size = 4\n",
    "    eval_batch_size = 4\n",
    "    num_sorted_samples = 1\n",
    "    num_epochs = 68 # one epoch needs ~12min (x2 GPU), because their are more training samples due connected_components\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 100 #500\n",
    "    evaluate_epochs = 4\n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_num_batches = 30 # one batch needs ~15s.  \n",
    "    evaluate_num_batches_3d = 2\n",
    "    evaluate_3D_epochs = 1000  # one 3D evaluation needs ~20min\n",
    "    save_model_epochs = 40\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-filling-256-cond-lesions\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\" \n",
    "    train_only_connected_masks=True\n",
    "    eval_only_connected_masks=False\n",
    "    num_inference_steps=50\n",
    "    log_csv = False\n",
    "    mode = \"train\" # train / eval\n",
    "    debug = True\n",
    "    brightness_augmentation = True\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    #hub_model_id = \"<your-username>/<my-awesome-model>\"  # the name of the repository to create on the HF Hub\n",
    "    #hub_private_repo = False\n",
    "    #overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f37af310-fb03-4445-a931-bc7e4f359ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.train_only_connected_masks=False\n",
    "    config.eval_only_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37e2ffca-7e8c-43d4-8e13-ba1900e38eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 10:01:11.335809: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-05 10:01:11.794556: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 10:01:11.794610: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 10:01:11.794662: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-05 10:01:11.962273: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-05 10:01:11.978209: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 10:01:27.074036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ac0c04de26404cb0407365f1e5399c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a16f7ae632b46fa9d44cd1d34b39745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:01<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e59afbbeb74e6ca0e8291afdb00596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "from pathlib import Path\n",
    "from torchvision import transforms \n",
    "\n",
    "#add augmentation\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    "\n",
    "#create dataset\n",
    "datasetTrain = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), root_dir_segm=Path(config.segm_train_path), root_dir_masks=Path(config.masks_train_path), only_connected_masks=config.train_only_connected_masks, t1n_target_shape=config.t1n_target_shape, transforms=transformations)\n",
    "datasetEvaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)\n",
    "dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b10865-fac0-4151-a227-d426c2fd20da",
   "metadata": {},
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6fe06-53ba-4056-bffb-c1c4acecacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get 6 random sample\n",
    "random_indices = np.random.randint(0, len(datasetTrain) - 1, size=(6)) \n",
    "\n",
    "# Plot: t1n images\n",
    "fig, axis = plt.subplots(2,3,figsize=(16,4))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    axis[i//3,i%3].imshow((datasetTrain[idx][\"gt_image\"].squeeze()+1)/2)\n",
    "    axis[i//3,i%3].set_axis_off()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116f7adb-e647-4260-a1cf-20bd8a3f2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: masks\n",
    "fig, axis = plt.subplots(2,3,figsize=(16,4))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    axis[i//3,i%3].imshow(datasetTrain[idx][\"mask\"].squeeze())\n",
    "    axis[i//3,i%3].set_axis_off()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43099f07-f1ff-46c1-bc83-2e448b80e778",
   "metadata": {},
   "source": [
    "### Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509adcf-a0b1-4652-a5ca-b398b008dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=3, # the number of input channels: 1 for img, 1 for img_voided, 1 for mask\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"UNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f67f7-b932-4f73-bdb3-96751ef6c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "#sample_image = datasetTrain[0]['gt_image'].unsqueeze(0)\n",
    "#noise = torch.randn(sample_image.shape)\n",
    "#timesteps = torch.LongTensor([50])\n",
    "#noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171c3aa-3a69-4dfa-bbb2-d3c8086fb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(datasetTrain)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cff9863-09e9-4951-a6d3-323cd9a15a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import TrainingConditional, DDIMInpaintPipeline, Evaluation2DFilling, Evaluation3DFilling\n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"Lesions\"\n",
    "\n",
    "args = {\n",
    "    \"config\": config, \n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"datasetTrain\": datasetTrain, \n",
    "    \"datasetEvaluation\": datasetEvaluation, \n",
    "    \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "    \"trainingCircularMasks\": False, \n",
    "    \"evaluation2D\": Evaluation2DFilling,\n",
    "    \"evaluation3D\": Evaluation3DFilling, \n",
    "    \"pipelineFactory\": PipelineFactories.get_ddim_inpaint_pipeline}\n",
    "trainingLesions = TrainingConditional(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba08bca-fc1f-431d-85ba-733f2a6f73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"train\":\n",
    "    trainingLesions.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f04c0c-2be6-4683-aae7-0bde77668354",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    pipeline = DDIMInpaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingLesions.evaluate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57c0c6-43be-4c06-90bc-3e50b56a8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fb612-dede-46d9-abd1-ed1cc23b01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create python script for ubelix\n",
    "!jupyter nbconvert --to script \"lesion_filling_conditioned_lesions.ipynb\"\n",
    "filename=\"lesion_filling_conditioned_lesions.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-18: \n",
    "            fp.write(line)\n",
    "# Deactivate Debug!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
