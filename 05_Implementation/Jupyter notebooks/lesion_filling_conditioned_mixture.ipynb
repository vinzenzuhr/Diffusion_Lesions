{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77b51cd-dfaa-44b4-b1f6-a36e07016f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config: \n",
    "    target_shape = None # will transform t1n during preprocessing (computationally expensive)\n",
    "    unet_img_shape = (256,256)\n",
    "    channels = 1\n",
    "    effective_train_batch_size=16 \n",
    "    eval_batch_size = 16 \n",
    "    sorted_slice_sample_size = 1\n",
    "    num_dataloader_workers = 8\n",
    "    num_epochs = 68 # one epoch needs ~12min (x2 GPU), because their are more training samples due connected_components\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 100 #500\n",
    "    evaluate_epochs = 4\n",
    "    deactivate2Devaluation = False\n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_num_batches = 30 # one batch needs ~15s.  \n",
    "    evaluate_num_batches_3d = 2\n",
    "    evaluate_unconditional_img = False\n",
    "    evaluate_3D_epochs = 1000  # one 3D evaluation needs ~20min \n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-filling-256-cond-mixture\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\" \n",
    "    train_connected_masks=True\n",
    "    eval_connected_masks=False\n",
    "    num_inference_steps=50\n",
    "    log_csv = False\n",
    "    mode = \"train\" # train / eval\n",
    "    debug = True\n",
    "    brightness_augmentation = True\n",
    "    restrict_mask_to_wm=True\n",
    "    proportion_training_circular_masks = 0.5\n",
    "    eval_loss_timesteps=[20,80,140,200,260,320,380,440,560,620,680,740,800,860,920,980]\n",
    "    restrict_train_slices = \"segm\"\n",
    "    restrict_eval_slices = \"mask\"\n",
    "    use_min_snr_loss=False\n",
    "    snr_gamma=5\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    #hub_model_id = \"<your-username>/<my-awesome-model>\"  # the name of the repository to create on the HF Hub\n",
    "    #hub_private_repo = False\n",
    "    #overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37e2ffca-7e8c-43d4-8e13-ba1900e38eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d98a516-6f3c-4d6e-8df8-2597ef20846f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "with open(Path.home() / \".cache/huggingface/accelerate/default_config.yaml\") as f:\n",
    "    data = json.load(f)\n",
    "    config.num_processes = data[\"num_processes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e4e3e6f-f59e-4844-a908-b21feae83211",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_batch_size = int((config.effective_train_batch_size / config.gradient_accumulation_steps) / config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f37af310-fb03-4445-a931-bc7e4f359ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.eval_loss_timesteps = [20]\n",
    "    config.train_connected_masks=False\n",
    "    config.eval_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\"\n",
    "    config.num_dataloader_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53f849e8-b970-435d-aa9e-a6b04c061f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with batch size 1, 1 accumulation steps and 1 process(es)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Start training with batch size {config.train_batch_size}, {config.gradient_accumulation_steps} accumulation steps and {config.num_processes} process(es)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-14 11:57:27.138642: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-14 11:57:27.328740: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-14 11:57:27.328797: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-14 11:57:27.328847: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-14 11:57:27.362460: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-14 11:57:27.376335: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-14 11:57:38.560432: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f0707e77ec4ddc9fc7688235dbb902",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f22a260da0924352bd64a3c22342e969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecee77542f274603838114c92daad08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "from pathlib import Path\n",
    "from torchvision import transforms \n",
    "\n",
    "#add augmentation\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    "\n",
    "#create dataset\n",
    "dataset_train = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), restriction=config.restrict_train_slices, root_dir_segm=Path(config.segm_train_path), root_dir_masks=Path(config.masks_train_path), connected_masks=config.train_connected_masks, target_shape=config.target_shape, transforms=transformations, restrict_mask_to_wm=config.restrict_mask_to_wm, proportion_training_circular_masks=config.proportion_training_circular_masks, circle_mask_shape=config.unet_img_shape)\n",
    "dataset_evaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), restriction=config.restrict_eval_slices, root_dir_masks=Path(config.masks_eval_path), connected_masks=config.eval_connected_masks, target_shape=config.target_shape)\n",
    "dataset_3D_evaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), connected_masks=config.eval_connected_masks, target_shape=config.target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43099f07-f1ff-46c1-bc83-2e448b80e778",
   "metadata": {},
   "source": [
    "### Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7509adcf-a0b1-4652-a5ca-b398b008dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=3, # the number of input channels: 1 for img, 1 for img_voided, 1 for mask\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"AttnDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"AttnUpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"BigUNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c05f67f7-b932-4f73-bdb3-96751ef6c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "#sample_image = datasetTrain[0]['gt_image'].unsqueeze(0)\n",
    "#noise = torch.randn(sample_image.shape)\n",
    "#timesteps = torch.LongTensor([50])\n",
    "#noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5171c3aa-3a69-4dfa-bbb2-d3c8086fb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(dataset_train)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e750167b-e2ba-4132-b46d-0a109506c3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator \n",
    "\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=config.mixed_precision,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f31ff4-2d41-43f9-93a9-6888fd19618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    if config.output_dir is not None:\n",
    "        os.makedirs(config.output_dir, exist_ok=True) \n",
    "    #setup tensorboard\n",
    "    tb_summary = SummaryWriter(config.output_dir, purge_step=0)\n",
    "    accelerator.init_trackers(\"train_example\") #maybe delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7844cbd4-a29a-41f7-98cb-85d332b2ea7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process:\n",
    "    from custom_modules import Logger\n",
    "    logger = Logger(tb_summary, config.log_csv)\n",
    "    logger.log_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e0845c8-029c-4cab-b90c-be9cb5478add",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import get_dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(dataset=dataset_train, batch_size = config.train_batch_size, \n",
    "                                  num_workers=config.num_dataloader_workers, random_sampler=True, \n",
    "                                  seed=config.seed, multi_slice=config.sorted_slice_sample_size > 1)\n",
    "d2_eval_dataloader = get_dataloader(dataset=dataset_evaluation, batch_size = config.eval_batch_size, \n",
    "                                    num_workers=config.num_dataloader_workers, random_sampler=False, \n",
    "                                    seed=config.seed, multi_slice=config.sorted_slice_sample_size > 1)\n",
    "d3_eval_dataloader = get_dataloader(dataset=dataset_3D_evaluation, batch_size = 1, \n",
    "                                    num_workers=config.num_dataloader_workers, random_sampler=False, \n",
    "                                    seed=config.seed, multi_slice=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aadc65be-ba62-454f-a449-fd7c10709609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import ModelInputGenerator, Evaluation2DFilling, Evaluation3DFilling \n",
    "\n",
    "model_input_generator = ModelInputGenerator(conditional=True, noise_scheduler=noise_scheduler)\n",
    " \n",
    "args = {\n",
    "    \"eval_dataloader\": d2_eval_dataloader, \n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"eval_loss_timesteps\": config.eval_loss_timesteps, \n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches, \n",
    "    \"seed\": config.seed\n",
    "}\n",
    "evaluation2D = Evaluation2DFilling(**args)\n",
    "args = {\n",
    "    \"dataloader\": d3_eval_dataloader, \n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"eval_batch_size\": config.eval_batch_size,\n",
    "    \"sorted_slice_sample_size\": config.sorted_slice_sample_size,\n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches_3d,\n",
    "    \"seed\": config.seed,\n",
    "}\n",
    "evaluation3D = Evaluation3DFilling(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9cff9863-09e9-4951-a6d3-323cd9a15a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import Training, DDIMInpaintPipeline, Evaluation2DFilling, Evaluation3DFilling\n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "args = { \n",
    "    \"accelerator\": accelerator,\n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"train_dataloader\": train_dataloader, \n",
    "    \"d2_eval_dataloader\": d2_eval_dataloader, \n",
    "    \"d3_eval_dataloader\": d3_eval_dataloader, \n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"evaluation2D\": evaluation2D,\n",
    "    \"evaluation3D\": evaluation3D,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger,\n",
    "    \"pipeline_factory\": PipelineFactories.get_ddim_inpaint_pipeline,\n",
    "    \"num_epochs\": config.num_epochs, \n",
    "    \"evaluate_2D_epochs\": config.evaluate_epochs,\n",
    "    \"evaluate_3D_epochs\": config.evaluate_3D_epochs,\n",
    "    \"min_snr_loss\": config.use_min_snr_loss,\n",
    "    \"snr_gamma\": config.snr_gamma,\n",
    "    \"evaluate_unconditional_img\": config.evaluate_unconditional_img,\n",
    "    \"deactivate_2D_evaluation\": config.deactivate2Devaluation, \n",
    "    \"deactivate_3D_evaluation\": config.deactivate3Devaluation, \n",
    "    \"evaluation_pipeline_parameters\": {},\n",
    "    \"debug\": config.debug, \n",
    "    }\n",
    "trainingMixture = Training(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dba08bca-fc1f-431d-85ba-733f2a6f73ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef022a502aac4c21a72fc47a7ffd9625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3570 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 77551) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1134\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/queues.py:113\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    112\u001b[0m timeout \u001b[38;5;241m=\u001b[39m deadline \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m--> 113\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:440\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_poll\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout):\n\u001b[0;32m--> 440\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbool\u001b[39m(r)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/multiprocessing/connection.py:939\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03mWait till an object in object_list is ready/readable.\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03mReturns list of those objects in object_list which are ready/readable.\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m--> 939\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_WaitSelector\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mselector\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobject_list\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/selectors.py:202\u001b[0m, in \u001b[0;36mBaseSelector.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[0;32m--> 202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/_utils/signal_handling.py:66\u001b[0m, in \u001b[0;36m_set_SIGCHLD_handler.<locals>.handler\u001b[0;34m(signum, frame)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandler\u001b[39m(signum, frame):\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# This following call uses `waitid` with WNOHANG from C side. Therefore,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# Python can still get and update the process status successfully.\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m     \u001b[43m_error_if_any_worker_fails\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m previous_handler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid 77551) is killed by signal: Killed. ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrainingMixture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/Training.py:154\u001b[0m, in \u001b[0;36mTraining.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain() \n\u001b[0;32m--> 154\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28minput\u001b[39m, noise, timesteps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_input_generator\u001b[38;5;241m.\u001b[39mget_model_input(batch)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# Predict the noise residual\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;66;03m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[38;5;66;03m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1296\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:1146\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1145\u001b[0m     pids_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(w\u001b[38;5;241m.\u001b[39mpid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) exited unexpectedly\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue\u001b[38;5;241m.\u001b[39mEmpty):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 77551) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "if config.mode == \"train\":\n",
    "    trainingMixture.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f04c0c-2be6-4683-aae7-0bde77668354",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    trainingMixture.deactivate_3D_evaluation = False\n",
    "    pipeline = DDIMInpaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingMixture.evaluate(pipeline, deactivate_save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57c0c6-43be-4c06-90bc-3e50b56a8701",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95fb612-dede-46d9-abd1-ed1cc23b01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create python script for ubelix\n",
    "!jupyter nbconvert --to script \"lesion_filling_conditioned_mixture.ipynb\"\n",
    "filename=\"lesion_filling_conditioned_mixture.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-18: \n",
    "            fp.write(line)\n",
    "# Deactivate Debug!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
