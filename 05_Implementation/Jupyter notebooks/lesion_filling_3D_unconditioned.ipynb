{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b277e45-ea4c-4639-9398-d22356d0222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './custom_modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1e0a8-8f60-4b1b-94b8-8367832dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig: \n",
    "    t1n_target_shape = None # will transform t1n during preprocessing (computationally expensive)\n",
    "    unet_img_shape = (256,256)\n",
    "    channels = 1\n",
    "    train_batch_size = 1 \n",
    "    eval_batch_size = 1 \n",
    "    num_sorted_samples = 3\n",
    "    num_epochs = 16 # 4.5s/iter, 21 min/epoch\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    evaluate_epochs = 1 # anpassen auf Anzahl epochs\n",
    "    evaluate_num_batches = 2 # one batch needs 4 min \n",
    "    evaluate_num_batches_3d = -1 \n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_3D_epochs = 1000  # one 3D evaluation has 77 slices and needs 166min\n",
    "    save_model_epochs = 40\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-filling-3D-repaint\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\"  \n",
    "    train_only_connected_masks=False  # No Training with lesion masks\n",
    "    eval_only_connected_masks=False \n",
    "    num_inference_steps=50 \n",
    "    log_csv = False\n",
    "    mode = \"train\" # train / eval\n",
    "    debug = True\n",
    "    jump_length=8\n",
    "    jump_n_sample=10 \n",
    "    brightness_augmentation = True\n",
    "    #uniform_dataset_path = \"./uniform_dataset\"\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    #hub_model_id = \"<your-username>/<my-awesome-model>\"  # the name of the repository to create on the HF Hub\n",
    "    #hub_private_repo = False\n",
    "    #overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc472c2-c374-4859-8ed5-791ebeafbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.train_only_connected_masks=False\n",
    "    config.eval_only_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\"  \n",
    "    config.num_sorted_samples=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521352b5-cf3f-41a2-b9c3-2fbf8c07c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750570d6616d45279162a69f4cecfed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e32265985144276a22798c7c9ebc170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756e0e2aaff04c80b84eb4b51a1a4abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from DatasetMRI2D import DatasetMRI2D\n",
    "from DatasetMRI3D import DatasetMRI3D\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from transform_utils import ScaleDecorator \n",
    "\n",
    "#add augmentation\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    "\n",
    "#create dataset\n",
    "datasetTrain = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), root_dir_segm=Path(config.segm_train_path), only_connected_masks=config.train_only_connected_masks, t1n_target_shape =config.t1n_target_shape, num_sorted_samples=config.num_sorted_samples, transforms=transformations, random_sorted_samples=True)\n",
    "datasetEvaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape =config.t1n_target_shape, num_sorted_samples=config.num_sorted_samples)\n",
    "dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape =config.t1n_target_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1188218d-a16d-4c0a-896f-e47a140bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from pseudo3D import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=config.channels,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"Pseudo3DDownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "        \"Pseudo3DAttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"Pseudo3DUpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"Pseudo3DAttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"Pseudo3DUNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4a40c63-4ba1-44aa-8c62-7f15ce816225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4f42d0a-9ebb-4437-b180-12b79af3c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(datasetTrain)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2ff284a-4306-4677-829e-98fef153fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 07:58:05.502538: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 07:58:06.992235: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 07:58:06.992293: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 07:58:06.997502: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 07:58:07.722328: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 07:58:07.726811: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 07:58:13.838005: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from TrainingUnconditional import TrainingUnconditional\n",
    "from RePaintPipeline import RePaintPipeline\n",
    "from Evaluation2DFilling import Evaluation2DFilling\n",
    "from Evaluation3DFilling import Evaluation3DFilling \n",
    "import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"None\"\n",
    "\n",
    "args = {\n",
    "    \"config\": config, \n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"datasetTrain\": datasetTrain, \n",
    "    \"datasetEvaluation\": datasetEvaluation, \n",
    "    \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "    \"evaluation2D\": Evaluation2DFilling,\n",
    "    \"evaluation3D\": Evaluation3DFilling, \n",
    "    \"pipelineFactory\": PipelineFactories.get_repaint_pipeline,\n",
    "    \"multi_sample\": config.num_sorted_samples > 1,\n",
    "    \"deactivate3Devaluation\": config.deactivate3Devaluation,\n",
    "    \"evaluation_pipeline_parameters\": {\n",
    "                \"jump_length\": config.jump_length,\n",
    "                \"jump_n_sample\": config.jump_n_sample,\n",
    "            }} \n",
    "\n",
    "training3Dlesions = TrainingUnconditional(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac4e0a-2837-4217-a97c-ce940bdc2151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb4bae549aeb46a5a9981275ac1b4f97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cf93ce9cb4a49e69f8f9f916c723b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/./custom_modules/RePaintPipeline.py:32: FutureWarning: The preprocess method is deprecated and will be removed in diffusers 1.0.0. Please use VaeImageProcessor.preprocess(...) instead\n",
      "  deprecate(\"preprocess\", \"1.0.0\", deprecation_message, standard_warn=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssim_full: 0.9965869188308716\n",
      "ssim_out: 0.9973406195640564\n",
      "ssim_in: 0.04748910292983055\n",
      "mse_full: 0.0005632618558593094\n",
      "mse_out: nan\n",
      "mse_in: 0.7098832726478577\n",
      "psnr_full: 38.51349639892578\n",
      "psnr_out: nan\n",
      "psnr_in: 7.508730888366699\n",
      "val_loss: 1.0928361415863037\n",
      "lpips: 0.025371478870511055\n",
      "global_step:  1\n",
      "image saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81edd957a6d425cb4c94ec570ffa85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config.mode == \"train\":\n",
    "    training3Dlesions.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be7971-c0ac-461d-9fcf-78481e7c9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    training3Dlesions.config.deactivate3Devaluation = False\n",
    "    pipeline = RePaintPipeline.from_pretrained(config.output_dir) \n",
    "    training3Dlesions.evaluate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e5c59-4c1c-4fc9-8ffc-4fddca8e2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be170a32-fcb6-41b1-b6ea-14b77eb7b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lesion_filling_3D_unconditioned.ipynb to script\n",
      "[NbConvertApp] Writing 7606 bytes to lesion_filling_3D_unconditioned.py\n"
     ]
    }
   ],
   "source": [
    "#create python script for ubelix \n",
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"lesion_filling_3D_unconditioned.ipynb\"\n",
    "filename=\"lesion_filling_3D_unconditioned.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
