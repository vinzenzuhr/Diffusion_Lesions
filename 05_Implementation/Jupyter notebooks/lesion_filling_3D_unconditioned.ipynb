{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b68cd1fb-7569-492f-bf55-afe48707f502",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Introduction\n",
    "In this jupyter notebook we're filling (removing) MS lesions. We're training an unconditional unet model with pseudo3D resnet blocks and then use the repaint pipeline to use the unconditional model for the inpainting task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3edc0b-0bc8-49d4-baaf-4d7240c8fd1c",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11f1e0a8-8f60-4b1b-94b8-8367832dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config: \n",
    "    mode = \"train\" # ['train', 'eval']\n",
    "    debug = True\n",
    "    output_dir = \"lesion-filling-3D-repaint\" \n",
    "\n",
    "    #dataset config\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\"  \n",
    "    target_shape = None # During preprocessing the img gets transformered to this shape (computationally expensive) \n",
    "    unet_img_shape = (256,256) # This defines the input layer of the model\n",
    "    channels = 1 # the number of input channels: 1 for grayscale img\n",
    "    restrict_train_slices = \"segm\" # Defines which 2D slices are used from the 3D MRI ['mask', 'segm', or 'unrestricted']\n",
    "    restrict_eval_slices = \"mask\" # Defines which 2D slices are used from the 3D MRI ['mask', 'segm', or 'unrestricted']\n",
    "    #restrict_mask_to_wm = False # Restricts lesion masks to white matter based on segmentation\n",
    "    #proportion_training_circular_masks = 0 # Defines if random circular masks should be used instead of the provided lesion masks. \n",
    "                                             # 1 is 100% random circular masks and 0 is 100% lesion masks.\n",
    "    #uniform_center_circular_masks = False # the center of the circular mask is uniform within a batch\n",
    "    #train_connected_masks = False # The distribution of the masks is extended by splitting the masks into several smaller connected components.  \t\n",
    "    brightness_augmentation = False\t# The training data gets augmented with randomly applied ColorJitter. \n",
    "    num_dataloader_workers = 8 # how many subprocesses to use for data loading\n",
    "\n",
    "    # train config \n",
    "    num_epochs = 150 \n",
    "    sorted_slice_sample_size = None # The number of sorted slices within one sample. Defaults to 1.\n",
    "                                    # This is needed for the pseudo3Dmodels, where the model expects that the slices within one batch\n",
    "                                    # are next to each other in the 3D volume.\n",
    "    train_batch_size = 1\n",
    "    effective_train_batch_size = 32 # The train_batch_size gets recalculated to this batch size based on accumulation_steps and number of GPU's.\n",
    "\t                                # For pseudo3D models the sorted_slice_sample_size gets calculcated to this batch size. \n",
    "                                    # The train_batch_size and eval_batch_size should be 1.\n",
    "    eval_batch_size = 1 \n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    use_min_snr_loss = True\n",
    "    snr_gamma = 5 \n",
    "    gradient_accumulation_steps = 1\n",
    "    mixed_precision = \"fp16\" # `no` for float32, `fp16` for automatic mixed precision \n",
    "\n",
    "    # evaluation config\n",
    "    num_inference_steps=50 \n",
    "    evaluate_2D_epochs = 3 # The interval at which to evaluate the model on 2D images. \n",
    "    evaluate_3D_epochs = 1000 # The interval at which to evaluate the model on 3D images.  \n",
    "    evaluate_num_batches = 4 # Number of batches used for evaluation. -1 means all batches. \n",
    "    evaluate_num_batches_3d = -1 # Number of batches used for evaluation. -1 means all batches.   \n",
    "    evaluate_unconditional_img = False # Used for unconditional models to generate some samples without the repaint pipeline. \n",
    "    deactivate_2D_evaluation = False\n",
    "    deactivate_3D_evaluation = True\n",
    "    img3D_filename = \"T1\" # Filename to save the processed 3D images \n",
    "    eval_loss_timesteps = [20,80,140,200,260,320,380,440,560,620,680,740,800,860,920,980] # List of timesteps to evalute validation loss.\n",
    "    eval_mask_dilation = 1 # dilation value for masks\n",
    "\t#add_lesion_technique = \"other_lesions_99Quantile\" # Used for synthesis only. \n",
    "                                                      # ['empty', 'mean_intensity', 'other_lesions_1stQuantile', 'other_lesions_mean', \n",
    "                                                      # 'other_lesions_median', 'other_lesions_3rdQuantile', 'other_lesions_99Quantile'] \n",
    "    #intermediate_timestep = 3 # Used for synthesis only. Diffusion process starts from this timesteps. \n",
    "                               # Num_inference_steps means the whole pipeline and 1 the last step. \n",
    "    jump_length = 8 # Used for unconditional lesion filling only. Defines the jump_length from the repaint paper.\n",
    "    jump_n_sample = 10 # Used for unconditional lesion filling only. Defines the jump_n_sample from the repaint paper.\n",
    "    log_csv = False # saves evaluation metrics as csv \n",
    "    seed = 0 # used for dataloader sampling and generation of the initial noise to start the diffusion process\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "423fbb75-1c12-46ee-9855-58caf35d43f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c223d4f-e72d-42c3-b949-8e9ceb38bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "with open(Path.home() / \".cache/huggingface/accelerate/default_config.yaml\") as f:\n",
    "    data = json.load(f)\n",
    "    config.num_processes = data[\"num_processes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f56316a-84fc-4621-8287-6bdf7b1ccce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.sorted_slice_sample_size = int((config.effective_train_batch_size / config.gradient_accumulation_steps) / config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fc472c2-c374-4859-8ed5-791ebeafbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps = 1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.eval_loss_timesteps = [20]\n",
    "    config.train_connected_masks = False\n",
    "    config.eval_connected_masks = False\n",
    "    config.evaluate_num_batches = 1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\"  \n",
    "    config.sorted_slice_sample_size = 1\n",
    "    config.num_dataloader_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3fc077d-11b2-4a29-8fb0-78c2e4f77f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with batch size 1, 1 accumulation steps and 1 process(es)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Start training with batch size {config.sorted_slice_sample_size}, {config.gradient_accumulation_steps} accumulation steps and {config.num_processes} process(es)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a90a6d3-5a70-4743-8eb4-02052c3ae373",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 15:16:16.127543: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-20 15:16:16.793901: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-20 15:16:16.793979: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-20 15:16:16.794056: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-20 15:16:16.937418: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-20 15:16:16.939217: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-20 15:16:29.654942: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9cc6fe3e09d46deb7a438723609752b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f3e0c9c98d47618eda4214e32241e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "from pathlib import Path\n",
    "from torchvision import transforms \n",
    " \n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    " \n",
    "dataset_train = DatasetMRI2D(\n",
    "    root_dir_img=Path(config.dataset_train_path), \n",
    "    root_dir_segm=Path(config.segm_train_path), \n",
    "    restriction=config.restrict_train_slices,   \n",
    "    transforms=transformations, \n",
    "    sorted_slice_sample_size=config.sorted_slice_sample_size, \n",
    "    target_shape =config.target_shape, \n",
    ")\n",
    "dataset_evaluation = DatasetMRI2D(\n",
    "    root_dir_img=Path(config.dataset_eval_path), \n",
    "    root_dir_masks=Path(config.masks_eval_path), \n",
    "    root_dir_segm=Path(config.segm_eval_path), \n",
    "    restriction=config.restrict_eval_slices, \n",
    "    dilation=config.eval_mask_dilation, \n",
    "    sorted_slice_sample_size=config.sorted_slice_sample_size, \n",
    "    target_shape =config.target_shape, \n",
    ")\n",
    "dataset_3D_evaluation = DatasetMRI3D(\n",
    "    root_dir_img=Path(config.dataset_eval_path), \n",
    "    root_dir_masks=Path(config.masks_eval_path), \n",
    "    root_dir_segm=Path(config.segm_eval_path), \n",
    "    dilation=config.eval_mask_dilation, \n",
    "    target_shape =config.target_shape, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83260fe3-171b-4a1e-9113-09e06846dccc",
   "metadata": {},
   "source": [
    "### Training environement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1188218d-a16d-4c0a-896f-e47a140bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  \n",
    "    in_channels=config.channels,  \n",
    "    out_channels=1,  \n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"Pseudo3DDownBlock2D\",  \n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "        \"Pseudo3DAttnDownBlock2D\", \n",
    "        \"Pseudo3DDownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"Pseudo3DUpBlock2D\", \n",
    "        \"Pseudo3DAttnUpBlock2D\", \n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "        \"Pseudo3DUpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"Pseudo3DUNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a40c63-4ba1-44aa-8c62-7f15ce816225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "# setup noise scheduler\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f42d0a-9ebb-4437-b180-12b79af3c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "# setup lr scheduler\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(dataset_train)/config.train_batch_size) * config.num_epochs),  \n",
    ")\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c6523-d22a-4ace-a370-e20dffa9723b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator \n",
    "\n",
    "# setup accelerator for distributed training\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=config.mixed_precision,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f97fcb-573c-4a39-be03-8dbc38aaf3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "from custom_modules import Logger\n",
    "\n",
    "# setup tensorboard\n",
    "if accelerator.is_main_process:\n",
    "    if config.output_dir is not None:\n",
    "        os.makedirs(config.output_dir, exist_ok=True) \n",
    "    tb_summary = SummaryWriter(config.output_dir, purge_step=0)\n",
    "    accelerator.init_trackers(\"train_example\") #maybe delete\n",
    "    logger = Logger(tb_summary, config.log_csv)\n",
    "    logger.log_config(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69f02a-e2dd-485c-8cc7-b1770ca1b597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import get_dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(\n",
    "    dataset=dataset_train, \n",
    "    batch_size=config.train_batch_size, \n",
    "    num_workers=config.num_dataloader_workers, \n",
    "    random_sampler=True, \n",
    "    seed=config.seed, \n",
    "    multi_slice=config.sorted_slice_sample_size > 1\n",
    ")\n",
    "d2_eval_dataloader = get_dataloader(\n",
    "    dataset=dataset_evaluation, \n",
    "    batch_size=config.eval_batch_size, \n",
    "    num_workers=config.num_dataloader_workers, \n",
    "    random_sampler=False, \n",
    "    seed=config.seed, \n",
    "    multi_slice=config.sorted_slice_sample_size > 1\n",
    ")\n",
    "d3_eval_dataloader = get_dataloader(\n",
    "    dataset=dataset_3D_evaluation, \n",
    "    batch_size=1, \n",
    "    num_workers=config.num_dataloader_workers,\n",
    "    random_sampler=False, \n",
    "    seed=config.seed, \n",
    "    multi_slice=False\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0129d-429a-4893-94f1-57d24a3139a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, d2_eval_dataloader, d3_eval_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, d2_eval_dataloader, d3_eval_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764f0567-296c-4067-b1e0-0300e94a8e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import ModelInputGenerator, Evaluation2DFilling, Evaluation3DFilling \n",
    "\n",
    "model_input_generator = ModelInputGenerator(conditional=False, noise_scheduler=noise_scheduler)\n",
    "\n",
    "args = {\n",
    "    \"eval_dataloader\": d2_eval_dataloader, \n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"eval_loss_timesteps\": config.eval_loss_timesteps, \n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches, \n",
    "    \"seed\": config.seed\n",
    "}\n",
    "evaluation2D = Evaluation2DFilling(**args)\n",
    "args = {\n",
    "    \"dataloader\": d3_eval_dataloader, \n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"filename\": config.img3D_filename,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"eval_batch_size\": config.eval_batch_size,\n",
    "    \"sorted_slice_sample_size\": config.sorted_slice_sample_size,\n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches_3d,\n",
    "    \"seed\": config.seed,\n",
    "}\n",
    "evaluation3D = Evaluation3DFilling(**args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cba585-449f-4cd8-aab4-d7e14b6e6304",
   "metadata": {},
   "source": [
    "### Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff284a-4306-4677-829e-98fef153fb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import Training, RePaintPipeline, Evaluation2DFilling, Evaluation3DFilling \n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"None\"\n",
    "\n",
    "args = { \n",
    "    \"accelerator\": accelerator,\n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"train_dataloader\": train_dataloader, \n",
    "    \"d2_eval_dataloader\": d2_eval_dataloader, \n",
    "    \"d3_eval_dataloader\": d3_eval_dataloader, \n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"evaluation2D\": evaluation2D,\n",
    "    \"evaluation3D\": evaluation3D,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger,\n",
    "    \"pipeline_factory\": PipelineFactories.get_repaint_pipeline,\n",
    "    \"num_epochs\": config.num_epochs, \n",
    "    \"evaluate_2D_epochs\": config.evaluate_2D_epochs,\n",
    "    \"evaluate_3D_epochs\": config.evaluate_3D_epochs,\n",
    "    \"min_snr_loss\": config.use_min_snr_loss,\n",
    "    \"snr_gamma\": config.snr_gamma,\n",
    "    \"evaluate_unconditional_img\": config.evaluate_unconditional_img,\n",
    "    \"deactivate_2D_evaluation\": config.deactivate_2D_evaluation, \n",
    "    \"deactivate_3D_evaluation\": config.deactivate_3D_evaluation, \n",
    "    \"evaluation_pipeline_parameters\": {\n",
    "        \"jump_length\": config.jump_length,\n",
    "        \"jump_n_sample\": config.jump_n_sample,\n",
    "    },\n",
    "    \"debug\": config.debug, \n",
    "    }\n",
    "\n",
    "training3Dlesions = Training(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac4e0a-2837-4217-a97c-ce940bdc2151",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"train\":\n",
    "    training3Dlesions.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be7971-c0ac-461d-9fcf-78481e7c9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    training3Dlesions.deactivate_3D_evaluation = False\n",
    "    pipeline = RePaintPipeline.from_pretrained(config.output_dir) \n",
    "    training3Dlesions.evaluate(pipeline, deactivate_save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07e5c59-4c1c-4fc9-8ffc-4fddca8e2bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd43c271-d41d-4a85-bc55-8ee6ececcf5f",
   "metadata": {},
   "source": [
    "### Save jupyter notebook as python script for hpc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be170a32-fcb6-41b1-b6ea-14b77eb7b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lesion_filling_3D_unconditioned.ipynb to script\n",
      "[NbConvertApp] Writing 14249 bytes to lesion_filling_3D_unconditioned.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"lesion_filling_3D_unconditioned.ipynb\"\n",
    "filename = \"lesion_filling_3D_unconditioned.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
