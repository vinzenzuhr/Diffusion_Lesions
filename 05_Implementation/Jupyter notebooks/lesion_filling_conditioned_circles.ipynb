{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a77b51cd-dfaa-44b4-b1f6-a36e07016f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config: \n",
    "    target_shape = None # will transform t1n during preprocessing (computationally expensive) \n",
    "    unet_img_shape = (256,256)\n",
    "    channels = 1\n",
    "    effective_train_batch_size=32 \n",
    "    eval_batch_size = 16\n",
    "    sorted_slice_sample_size = 1\n",
    "    num_dataloader_workers = 8\n",
    "    num_epochs = 900 # nochmals einsch√§tzen\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500 #500\n",
    "    evaluate_epochs = 18 #30\n",
    "    deactivate2Devaluation = False\n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_num_batches = 30 # one batch needs ~15s. \n",
    "    evaluate_num_batches_3d = -1  \n",
    "    evaluate_unconditional_img = False\n",
    "    evaluate_3D_epochs = 1000  # one 3D evaluation needs ~20min \n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-filling-256-cond-circle\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/filling/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/filling/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/filling/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/filling/dataset_eval/masks\" \n",
    "    train_connected_masks=False # No Training with lesion masks\n",
    "    eval_connected_masks=False \n",
    "    num_inference_steps=50\n",
    "    log_csv = False\n",
    "    mode = \"train\" # train / eval\n",
    "    debug = True\n",
    "    brightness_augmentation = True\n",
    "    proportion_training_circular_masks = 1.0\n",
    "    eval_loss_timesteps=[20,80,140,200,260,320,380,440,560,620,680,740,800,860,920,980]\n",
    "    restrict_train_slices = \"segm\"\n",
    "    restrict_eval_slices = \"mask\"\n",
    "    use_min_snr_loss=False\n",
    "    snr_gamma=5\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub\n",
    "    #hub_model_id = \"<your-username>/<my-awesome-model>\"  # the name of the repository to create on the HF Hub\n",
    "    #hub_private_repo = False\n",
    "    #overwrite_output_dir = True  # overwrite the old model when re-running the notebook\n",
    "    seed = 0\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "769139d8-bc94-46d9-9acf-ce00ea6edecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5794453d-5ae4-4498-b35a-105d6ed4e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "with open(Path.home() / \".cache/huggingface/accelerate/default_config.yaml\") as f:\n",
    "    data = json.load(f)\n",
    "    config.num_processes = data[\"num_processes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ddee880-4bf5-4651-bc27-c29691fb7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_batch_size = int((config.effective_train_batch_size / config.gradient_accumulation_steps) / config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d5a5223-3c9a-4287-b44a-1a6c1a411538",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps=1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1 \n",
    "    config.eval_loss_timesteps = [20]\n",
    "    config.train_connected_masks=False\n",
    "    config.eval_connected_masks=False\n",
    "    config.evaluate_num_batches=1\n",
    "    config.dataset_train_path = \"./datasets/filling/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/filling/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/filling/dataset_eval/masks\"\n",
    "    config.num_dataloader_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcee9aef-142e-4aa2-8409-ba59b4e7c97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training with batch size 1, 1 accumulation steps and 1 process(es)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Start training with batch size {config.train_batch_size}, {config.gradient_accumulation_steps} accumulation steps and {config.num_processes} process(es)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 09:34:52.273610: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-12 09:34:52.635558: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-12 09:34:52.635615: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-12 09:34:52.635660: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-12 09:34:52.688946: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-06-12 09:34:52.703133: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 09:35:04.901554: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pseudo3D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms \n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/__init__.py:15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mGuidedPipelineUnconditional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GuidedPipelineUnconditional\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mDDIMInpaintPipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DDIMInpaintPipeline\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEvaluation2D\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluation2D \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEvaluation2DFilling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluation2DFilling\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEvaluation2DSynthesis\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Evaluation2DSynthesis\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/Evaluation2D.py:15\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_pil_image\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationUtils, Training \n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEvaluation2D\u001b[39;00m(ABC):\n\u001b[1;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;124;03m    Abstract class for evaluating the performance of a 2D diffusion pipeline with 2D images.\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;124;03m        accelerator (Accelerator): Accelerator object for distributed training.\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/custom_modules/Training.py:17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_dataloader, DatasetMRI2D, DatasetMRI3D, Evaluation2D, Evaluation3D\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpseudo3D\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mTraining\u001b[39;00m(ABC):\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m    Abstract base class for training a model.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m        min_snr_loss (bool): A boolean indicating whether to use the minimum SNR loss. Default is False.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pseudo3D'"
     ]
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "\n",
    "from pathlib import Path\n",
    "from torchvision import transforms \n",
    "\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    "\n",
    "#create dataset\n",
    "dataset_train = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), restriction=config.restrict_train_slices, root_dir_segm=Path(config.segm_train_path), connected_masks=config.train_connected_masks, target_shape=config.target_shape, transforms=transformations, proportion_training_circular_masks=config.proportion_training_circular_masks, circle_mask_shape=config.unet_img_shape)\n",
    "dataset_evaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), restriction=config.restrict_eval_slices, root_dir_masks=Path(config.masks_eval_path), connected_masks=config.eval_connected_masks, target_shape=config.target_shape)\n",
    "dataset_3D_evaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), connected_masks=config.eval_connected_masks, target_shape=config.target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b10865-fac0-4151-a227-d426c2fd20da",
   "metadata": {},
   "source": [
    "### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a6286c-155d-4d6c-923d-bef8ce0b180c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig, axis = plt.subplots(1,2,figsize=(16,4))\n",
    "idx=80\n",
    "axis[0].imshow((dataset_train[idx][\"gt_image\"].squeeze()+1)/2)\n",
    "axis[1].imshow(np.logical_or(dataset_train[idx][\"segm\"].squeeze()==41, dataset_train[idx][\"segm\"].squeeze()==2))\n",
    "fig.show "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c57471-c0bf-4bca-9207-4dc6194bd17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 6 random sample\n",
    "random_indices = np.random.randint(0, len(dataset_train) - 1, size=(6)) \n",
    "\n",
    "# Plot: t1n segmentations\n",
    "fig, axis = plt.subplots(2,3,figsize=(16,4))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    axis[i//3,i%3].imshow(np.logical_or(dataset_train[idx][\"segm\"].squeeze()==41, dataset_train[idx][\"segm\"].squeeze()==2))\n",
    "    axis[i//3,i%3].set_axis_off()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6fe06-53ba-4056-bffb-c1c4acecacb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot: t1n images\n",
    "fig, axis = plt.subplots(2,3,figsize=(16,4))\n",
    "for i, idx in enumerate(random_indices):\n",
    "    axis[i//3,i%3].imshow((dataset_train[idx][\"gt_image\"].squeeze()+1)/2)\n",
    "    axis[i//3,i%3].set_axis_off()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba21352-9edc-4351-a359-de83bbed114d",
   "metadata": {},
   "source": [
    "### Playground for random circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18221bb-ac64-4876-9a87-24a8c0ff7cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize normal distributions of center points\n",
    "centers=[]\n",
    "for _ in np.arange(100):\n",
    "    centers.append(torch.normal(torch.tensor([127.,127.]),torch.tensor(30.)))\n",
    "\n",
    "plt.imshow((dataset_train[70][\"gt_image\"].squeeze()+1)/2) \n",
    "for center in centers:\n",
    "    plt.scatter(center[0], center[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6508289-04f3-46c8-bc05-9629d7799e27",
   "metadata": {},
   "outputs": [],
   "source": [
    "example=torch.zeros((10,256,256)).shape\n",
    "\n",
    "#create circular mask with random center around the center point of the pictures and a radius between 3 and 40 pixels\n",
    "center=np.random.normal([127,127],30, size=(example[0],2))\n",
    "radius=np.random.uniform(low=3,high=40, size=(example[0]))\n",
    "\n",
    "Y, X = np.ogrid[:256, :256] # gives two vectors, each containing the pixel locations. There's a column vector for the column indices and a row vector for the row indices.\n",
    "dist_from_center = np.sqrt((X.T - center[:,0])[None,:,:]**2 + (Y-center[:,1])[:,None,:]**2) # creates matrix with euclidean distance to center\n",
    "\n",
    "mask = dist_from_center <= radius # creates mask for pixels which are inside the radius\n",
    "mask = 1-mask\n",
    "\n",
    "plt.imshow(((dataset_train[70][\"gt_image\"].squeeze()+1)/2)*mask[:,:,4]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43099f07-f1ff-46c1-bc83-2e448b80e778",
   "metadata": {},
   "source": [
    "### Prepare Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7509adcf-a0b1-4652-a5ca-b398b008dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=3, # the number of input channels: 1 for img, 1 for img_voided, 1 for mask\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"UNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05f67f7-b932-4f73-bdb3-96751ef6c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "#sample_image = datasetTrain[0]['gt_image'].unsqueeze(0)\n",
    "#noise = torch.randn(sample_image.shape)\n",
    "#timesteps = torch.LongTensor([50])\n",
    "#noisy_image = noise_scheduler.add_noise(sample_image, noise, timesteps)\n",
    "\n",
    "#tb_summary.add_text(\"noise_scheduler\", \"DDIMScheduler(num_train_timesteps=1000)\", 0) \n",
    "\n",
    "#Image.fromarray(((noisy_image.permute(0, 2, 3, 1) + 1.0) * 127.5).type(torch.uint8).numpy()[0])\n",
    "\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5171c3aa-3a69-4dfa-bbb2-d3c8086fb1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(dataset_train)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc6fd48-0837-4efe-94d6-d13bbbf73d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator \n",
    "\n",
    "accelerator = Accelerator(\n",
    "    mixed_precision=config.mixed_precision,\n",
    "    gradient_accumulation_steps=config.gradient_accumulation_steps,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "067e1948-657c-408d-8631-405f05120320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    if config.output_dir is not None:\n",
    "        os.makedirs(config.output_dir, exist_ok=True) \n",
    "    #setup tensorboard\n",
    "    tb_summary = SummaryWriter(config.output_dir, purge_step=0)\n",
    "    accelerator.init_trackers(\"train_example\") #maybe delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3068fb92-d0cf-4bdd-b4f1-6377348e8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "if accelerator.is_main_process:\n",
    "    from custom_modules import Logger\n",
    "    logger = Logger(tb_summary, config.log_csv)\n",
    "    logger.log_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b646d9fb-4d07-49a8-b209-11907f3afd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import get_dataloader\n",
    "\n",
    "train_dataloader = get_dataloader(dataset=dataset_train, batch_size = config.train_batch_size, \n",
    "                                  num_workers=config.num_dataloader_workers, random_sampler=True, \n",
    "                                  seed=config.seed, multi_slice=config.sorted_slice_sample_size > 1)\n",
    "d2_eval_dataloader = get_dataloader(dataset=dataset_evaluation, batch_size = config.eval_batch_size, \n",
    "                                    num_workers=config.num_dataloader_workers, random_sampler=False, \n",
    "                                    seed=config.seed, multi_slice=config.sorted_slice_sample_size > 1)\n",
    "d3_eval_dataloader = get_dataloader(dataset=dataset_3D_evaluation, batch_size = 1, \n",
    "                                    num_workers=config.num_dataloader_workers, random_sampler=False, \n",
    "                                    seed=config.seed, multi_slice=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8e72dd0-33df-43da-8552-5657d2083b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_modules import ModelInputGenerator, Evaluation2DFilling, Evaluation3DFilling \n",
    "\n",
    "model_input_generator = ModelInputGenerator(conditional=True, noise_scheduler=noise_scheduler)\n",
    " \n",
    "args = {\n",
    "    \"eval_dataloader\": d2_eval_dataloader, \n",
    "    \"train_dataloader\": train_dataloader,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"eval_loss_timesteps\": config.eval_loss_timesteps, \n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches, \n",
    "    \"seed\": config.seed\n",
    "}\n",
    "evaluation2D = Evaluation2DFilling(**args)\n",
    "args = {\n",
    "    \"dataloader\": d3_eval_dataloader, \n",
    "    \"logger\": None if not accelerator.is_main_process else logger, \n",
    "    \"accelerator\": accelerator,\n",
    "    \"output_dir\": config.output_dir,\n",
    "    \"num_inference_steps\": config.num_inference_steps,\n",
    "    \"eval_batch_size\": config.eval_batch_size,\n",
    "    \"sorted_slice_sample_size\": config.sorted_slice_sample_size,\n",
    "    \"evaluate_num_batches\": config.evaluate_num_batches_3d,\n",
    "    \"seed\": config.seed,\n",
    "}\n",
    "evaluation3D = Evaluation3DFilling(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c40b1603-390b-48b7-81fc-6d0bd96dbe25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accelerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Training, DDIMInpaintPipeline, Evaluation2DFilling, Evaluation3DFilling  \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcustom_modules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PipelineFactories\n\u001b[1;32m      4\u001b[0m args \u001b[38;5;241m=\u001b[39m { \n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccelerator\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43maccelerator\u001b[49m,\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model, \n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnoise_scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m: noise_scheduler, \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptimizer\u001b[39m\u001b[38;5;124m\"\u001b[39m: optimizer, \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr_scheduler\u001b[39m\u001b[38;5;124m\"\u001b[39m: lr_scheduler, \n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_dataloader, \n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md2_eval_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: d2_eval_dataloader, \n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124md3_eval_dataloader\u001b[39m\u001b[38;5;124m\"\u001b[39m: d3_eval_dataloader, \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_input_generator\u001b[39m\u001b[38;5;124m\"\u001b[39m: model_input_generator,\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation2D\u001b[39m\u001b[38;5;124m\"\u001b[39m: evaluation2D,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation3D\u001b[39m\u001b[38;5;124m\"\u001b[39m: evaluation3D,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlogger\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m accelerator\u001b[38;5;241m.\u001b[39mis_main_process \u001b[38;5;28;01melse\u001b[39;00m logger,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpipeline_factory\u001b[39m\u001b[38;5;124m\"\u001b[39m: PipelineFactories\u001b[38;5;241m.\u001b[39mget_ddim_inpaint_pipeline,\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mnum_epochs, \n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate_2D_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mevaluate_epochs,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate_3D_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mevaluate_3D_epochs,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_snr_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39muse_min_snr_loss,\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msnr_gamma\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39msnr_gamma,\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluate_unconditional_img\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mevaluate_unconditional_img,\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeactivate_2D_evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mdeactivate2Devaluation, \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeactivate_3D_evaluation\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mdeactivate3Devaluation, \n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation_pipeline_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m: {},\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdebug\u001b[39m\u001b[38;5;124m\"\u001b[39m: config\u001b[38;5;241m.\u001b[39mdebug, \n\u001b[1;32m     28\u001b[0m     }\n\u001b[1;32m     29\u001b[0m trainingCircles \u001b[38;5;241m=\u001b[39m Training(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs) \n",
      "\u001b[0;31mNameError\u001b[0m: name 'accelerator' is not defined"
     ]
    }
   ],
   "source": [
    "from custom_modules import Training, DDIMInpaintPipeline, Evaluation2DFilling, Evaluation3DFilling  \n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "args = { \n",
    "    \"accelerator\": accelerator,\n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"train_dataloader\": train_dataloader, \n",
    "    \"d2_eval_dataloader\": d2_eval_dataloader, \n",
    "    \"d3_eval_dataloader\": d3_eval_dataloader, \n",
    "    \"model_input_generator\": model_input_generator,\n",
    "    \"evaluation2D\": evaluation2D,\n",
    "    \"evaluation3D\": evaluation3D,\n",
    "    \"logger\": None if not accelerator.is_main_process else logger,\n",
    "    \"pipeline_factory\": PipelineFactories.get_ddim_inpaint_pipeline,\n",
    "    \"num_epochs\": config.num_epochs, \n",
    "    \"evaluate_2D_epochs\": config.evaluate_epochs,\n",
    "    \"evaluate_3D_epochs\": config.evaluate_3D_epochs,\n",
    "    \"min_snr_loss\": config.use_min_snr_loss,\n",
    "    \"snr_gamma\": config.snr_gamma,\n",
    "    \"evaluate_unconditional_img\": config.evaluate_unconditional_img,\n",
    "    \"deactivate_2D_evaluation\": config.deactivate2Devaluation, \n",
    "    \"deactivate_3D_evaluation\": config.deactivate3Devaluation, \n",
    "    \"evaluation_pipeline_parameters\": {},\n",
    "    \"debug\": config.debug, \n",
    "    }\n",
    "trainingCircles = Training(**args) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe29460-8363-4f7e-aeac-5944ebebc660",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"train\":\n",
    "    trainingCircles.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9106d1-bf7b-4ec0-bd4c-e980051e7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    trainingCircles.deactivate_3D_evaluation = False\n",
    "    pipeline = DDIMInpaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingCircles.evaluate(pipeline, deactivate_save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f790341-a14e-44fe-bfce-a88dec97707c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf38b5e5-8e55-4e55-b756-4bfd75248e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create python script for ubelix\n",
    "!jupyter nbconvert --to script \"lesion_filling_conditioned_circles.ipynb\"\n",
    "filename=\"lesion_filling_conditioned_circles.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
