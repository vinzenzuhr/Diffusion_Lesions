{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f1e0a8-8f60-4b1b-94b8-8367832dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig: \n",
    "    t1n_target_shape = None # will transform t1n during preprocessing (computationally expensive)\n",
    "    unet_img_shape = (160,256)\n",
    "    channels = 1\n",
    "    effective_train_batch_size=16 \n",
    "    eval_batch_size = 4  \n",
    "    num_sorted_samples = 1\n",
    "    num_dataloader_workers = 8\n",
    "    num_epochs = 192\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    evaluate_epochs = 5 # adjust to num_epochs\n",
    "    evaluate_num_batches = -1 # ~3s/batch. 2.5 min/Evaluation 3D epoch with all batchesr\n",
    "    evaluate_num_batches_3d = -1 \n",
    "    deactivate2Devaluation = False\n",
    "    deactivate3Devaluation = True\n",
    "    evaluate_3D_epochs = 1000  # 3 min/Evaluation 3D \n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-synthesis-256-unconditioned\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/synthesis/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/synthesis/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/synthesis/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/synthesis/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/synthesis/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/synthesis/dataset_eval/masks\"\n",
    "    train_only_connected_masks=False  # No Training with lesion masks\n",
    "    eval_only_connected_masks=False \n",
    "    num_inference_steps=50\n",
    "    log_csv = True\n",
    "    add_lesion_technique = \"other_lesions_99Quantile\" # 'mean_intensity', 'other_lesions_1stQuantile', 'other_lesions_mean', 'other_lesions_median', 'other_lesions_3rdQuantile', 'other_lesions_99Quantile'\n",
    "    add_lesion_mean_intensity = -0.5492 \n",
    "    intermediate_timestep = 3 # starting from this timesteps. num_inference_steps means the whole pipeline and 1 the last step. \n",
    "    mode = \"train\" # 'train', 'eval' or \"tuning_parameters\"\n",
    "    debug = True     \n",
    "    jump_length=intermediate_timestep\n",
    "    jump_n_sample=3\n",
    "    brightness_augmentation = False\n",
    "    eval_loss_timesteps=[20,40,80,140]\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub \n",
    "    seed = 0\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f1f4a9f-d91e-479c-ae33-8fe3b58d992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)\n",
    "#if there are problems with ports then add manually \"main_process_port: 0\" or another number to yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ef574b-c7e4-4588-b194-cb41cfda8193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "with open(Path.home() / \".cache/huggingface/accelerate/default_config.yaml\") as f:\n",
    "    data = json.load(f)\n",
    "    config.num_processes = data[\"num_processes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b28bb93-5c54-42e5-ac9b-38c26a3a96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.train_batch_size = int((config.effective_train_batch_size / config.gradient_accumulation_steps) / config.num_processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc472c2-c374-4859-8ed5-791ebeafbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps = 1\n",
    "    config.intermediate_timestep = 1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1\n",
    "    config.eval_loss_timesteps = [20]\n",
    "    config.train_only_connected_masks=False\n",
    "    config.eval_only_connected_masks=False\n",
    "    config.evaluate_num_batches = 3\n",
    "    config.deactivate3Devaluation = False\n",
    "    config.dataset_train_path = \"./datasets/synthesis/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/synthesis/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/synthesis/dataset_eval/masks\" \n",
    "    config.num_dataloader_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f6d3-517a-48ab-a8ff-7c8e869080af",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(config.eval_loss_timesteps) == config.eval_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-05 10:01:11.342972: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-05 10:01:11.794556: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-05 10:01:11.794610: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-05 10:01:11.794657: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-05 10:01:11.962273: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-05 10:01:11.965137: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-05 10:01:27.072998: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cf3e580a34747de803f8eff7222ebd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c6121b503f34371a2c658d066ab3b5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "963c1949027748898f78d411851dd148",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "from pathlib import Path\n",
    "from torchvision import transforms \n",
    "\n",
    "#add augmentation\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    "\n",
    "#create dataset\n",
    "datasetTrain = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), root_dir_segm=Path(config.segm_train_path), only_connected_masks=config.train_only_connected_masks, t1n_target_shape=config.t1n_target_shape, transforms=transformations)\n",
    "datasetEvaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), root_dir_synthesis=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)\n",
    "dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), root_dir_synthesis=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885175f-4240-49fd-b199-061a3c5ea94e",
   "metadata": {},
   "source": [
    "### Finding good intensity of lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a84b00f-2c7b-4583-b9e3-91238db9e391",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f407af9f7842aa8c44a298c1ed28b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38808b05e6204190a0912021fa81e97b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     30\u001b[0m     t1ws\u001b[38;5;241m.\u001b[39mappend(t1w)\n\u001b[1;32m     31\u001b[0m     lesions\u001b[38;5;241m.\u001b[39mappend(lesion)\n\u001b[0;32m---> 32\u001b[0m t1w_big \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mcat(t1ws)\n\u001b[1;32m     33\u001b[0m lesion_big \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(lesions)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean lesion intensity: \u001b[39m\u001b[38;5;124m\"\u001b[39m, t1w_big[lesion_big\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mbool)]\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;66;03m# -0.3572\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from tqdm.auto import tqdm \n",
    "from custom_modules import DatasetMRI2D, DatasetMRI3D, ScaleDecorator\n",
    "\n",
    "#skip to speed up\n",
    "if False:\n",
    "    #t1w_norm_noskull_list = list(Path(\"temp/unhealthy_DL+DiReCT_Segmentation\").rglob(\"*T1w_norm_noskull.nii.gz\"))\n",
    "    #lesion_list = list(Path(\"temp/unhealthy_registered_lesions\").rglob(\"*transformed_lesion.nii.gz\"))\n",
    "    #t1w_norm_noskull_list = list(Path(\"datasets_full/unhealthy_flair\").rglob(\"*3DFLAIR.nii.gz\"))\n",
    "    #lesion_list = list(Path(\"datasets_full/unhealthy_flair_masks\").rglob(\"*Consensus.nii.gz\"))\n",
    "\n",
    "    dataset_eval_path=\"datasets_full/unhealthy_flair\"\n",
    "    masks_eval_path=\"datasets_full/unhealthy_flair_masks\"\n",
    "    \n",
    "    dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(dataset_eval_path), root_dir_masks=Path(masks_eval_path), root_dir_synthesis=Path(masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)\n",
    "    \n",
    "    t1ws = list()\n",
    "    lesions = list()\n",
    "    for i in tqdm(range(len(dataset3DEvaluation))):\n",
    "        t1w = dataset3DEvaluation[i][\"gt_image\"]\n",
    "        lesion = dataset3DEvaluation[i][\"mask\"]\n",
    "        \n",
    "        #t1w = t1w.get_fdata()\n",
    "        #t1w, _, lesion, _, _ = DatasetMRI3D.preprocess(t1w, masks=lesion)\n",
    "        #lesion = lesion.get_fdata()\n",
    "        #lesion = DatasetMRI3D._padding(torch.from_numpy(lesion).to(torch.uint8))\n",
    "        #means.append(t1w[lesion.to(torch.bool)].mean())\n",
    "        #stds.append(t1w[lesion.to(torch.bool)].std())\n",
    "        t1ws.append(t1w)\n",
    "        lesions.append(lesion)\n",
    "    t1w_big = torch.cat(t1ws)\n",
    "    lesion_big = torch.cat(lesions)\n",
    "    \n",
    "    print(\"mean lesion intensity: \", t1w_big[lesion_big.to(torch.bool)].mean()) # -0.3572\n",
    "    print(\"std lesion intensity: \", t1w_big[lesion_big.to(torch.bool)].std()) # 0.1829\n",
    "    print(\"median lesion intensity: \", t1w_big[lesion_big.to(torch.bool)].median()) # 0.1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46ce44b1-5aa0-4760-b79f-0dab3be0cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    " \n",
    "\n",
    "#skip to speed up\n",
    "if False: \n",
    "    random_idx = torch.randint(len(datasetEvaluation)-1, size=(1,)).item()\n",
    "    \n",
    "    fig, axis = plt.subplots(1,4, figsize=(16,4)) \n",
    "    img = datasetEvaluation[random_idx][\"gt_image\"].squeeze()\n",
    "    img[datasetEvaluation[random_idx][\"mask\"].to(torch.bool).squeeze()] = -0.5492 # mean-std of lesion intensity\n",
    "    axis[0].imshow(datasetEvaluation[random_idx][\"gt_image\"].squeeze()/2+0.5)\n",
    "    axis[0].set_axis_off()\n",
    "    axis[1].imshow(datasetEvaluation[random_idx][\"mask\"].squeeze())\n",
    "    axis[1].set_axis_off()\n",
    "    axis[2].imshow(img/2+0.5)\n",
    "    axis[2].set_axis_off()\n",
    "    axis[3].imshow(datasetEvaluation[random_idx][\"synthesis\"].squeeze())\n",
    "    axis[3].set_axis_off()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c744a-8c9f-42fb-9342-f7735c5b5032",
   "metadata": {},
   "source": [
    "### Playground LPIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da88e984-791b-4fc7-8f3a-61ea3dd1d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip to speed up\n",
    "if False:\n",
    "    from Evaluation2DSynthesis import Evaluation2DSynthesis\n",
    "    from accelerate import Accelerator\n",
    "    from DDIMGuidedPipeline import DDIMGuidedPipeline\n",
    "    \n",
    "    pipeline = DDIMGuidedPipeline.from_pretrained(config.output_dir) \n",
    "    \n",
    "    eval = Evaluation2DSynthesis(config, pipeline, None, None, Accelerator(), None)\n",
    "    images_with_lesions, _ = eval._add_coarse_lesions(datasetEvaluation[123][\"gt_image\"], datasetEvaluation[123])\n",
    "    clean_image=datasetEvaluation[123][\"gt_image\"]\n",
    "    synthesized_images = pipeline(images_with_lesions, 1).images\n",
    "    synthesized_images_2 = pipeline(images_with_lesions, 3).images\n",
    "    print(\"Pips for one timestep: \", eval._calc_lpip(clean_image.unsqueeze(0), synthesized_images))\n",
    "    print(\"Pips for three timestep: \", eval._calc_lpip(clean_image.unsqueeze(0), synthesized_images_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42d4edd7-5123-42f2-8a98-5b4c1c464164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip to speed up\n",
    "if False:\n",
    "    fig, axis = plt.subplots(1,4, figsize=(24,12))\n",
    "    axis[0].imshow(clean_image.squeeze()/2+0.5)\n",
    "    axis[0].set_title(\"original image\")\n",
    "    axis[1].imshow(images_with_lesions.squeeze()/2+0.5)\n",
    "    axis[1].set_title(\"coarse lesions\")\n",
    "    axis[2].imshow(synthesized_images.squeeze()/2+0.5)\n",
    "    axis[2].set_title(\"Diffusion with one timestep\")\n",
    "    axis[3].imshow(synthesized_images_2.squeeze()/2+0.5)\n",
    "    axis[3].set_title(\"Diffusion with three timestep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a086dd-5273-4c44-aa62-e9cd98a0c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip to speed up\n",
    "if False:\n",
    "    diff_1=clean_image-synthesized_images\n",
    "    diff_3=clean_image-synthesized_images_2\n",
    "    fig, axis = plt.subplots(1,2, figsize=(16,8))\n",
    "    axis[0].imshow(diff_1.squeeze()/2+0.5)\n",
    "    axis[0].set_title(\"Differences with one timestep\")\n",
    "    axis[1].imshow(diff_3.squeeze()/2+0.5)\n",
    "    axis[1].set_title(\"Differences with three timestep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799bdb3-4c83-4ab8-8e46-33d2fe30f49d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1188218d-a16d-4c0a-896f-e47a140bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=config.channels,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"UNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4a40c63-4ba1-44aa-8c62-7f15ce816225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4f42d0a-9ebb-4437-b180-12b79af3c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(datasetTrain)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2ff284a-4306-4677-829e-98fef153fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from custom_modules import TrainingUnconditional, GuidedRePaintPipeline, Evaluation2DSynthesis, Evaluation3DSynthesis \n",
    "from custom_modules import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"None\"\n",
    "\n",
    "args = {\n",
    "    \"config\": config, \n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"datasetTrain\": datasetTrain, \n",
    "    \"datasetEvaluation\": datasetEvaluation, \n",
    "    \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "    \"evaluation2D\": Evaluation2DSynthesis,\n",
    "    \"evaluation3D\": Evaluation3DSynthesis, \n",
    "    \"pipelineFactory\": PipelineFactories.get_guided_repaint_pipeline, \n",
    "    \"deactivate3Devaluation\": config.deactivate3Devaluation,\n",
    "    \"evaluation_pipeline_parameters\": {\n",
    "                \"jump_length\": config.jump_length,\n",
    "                \"jump_n_sample\": config.jump_n_sample,\n",
    "            }} \n",
    "trainingSynthesis = TrainingUnconditional(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac4e0a-2837-4217-a97c-ce940bdc2151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52fc598027a947de887455e56558ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if config.mode == \"train\":\n",
    "    trainingSynthesis.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be7971-c0ac-461d-9fcf-78481e7c9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    trainingSynthesis.config.deactivate3Devaluation = False\n",
    "    pipeline = GuidedRePaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingSynthesis.evaluate(pipeline, deactivate_save_model=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e6ddc-f89d-451d-9a79-4edc40c05230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if config.mode == \"tuning_parameters\":\n",
    "    trainingSynthesis.config.deactivate3Devaluation = False\n",
    "    pipeline = GuidedRePaintPipeline.from_pretrained(config.output_dir)\n",
    "    original_output_dir = config.output_dir \n",
    "    timesteps = [1, 3, 5]\n",
    "    resample_step = [1, 3, 5]\n",
    "    parameters = product(timesteps, resample_step) \n",
    "    \n",
    "    for timestep, resample_step in parameters:\n",
    "        print(\"Begin evaluation for timestep \", timestep, \" and resample step \", resample_step)\n",
    "        trainingSynthesis.config.intermediate_timestep = timestep\n",
    "        trainingSynthesis.config.jump_length = timestep\n",
    "        trainingSynthesis.config.jump_n_sample = resample_step\n",
    "        trainingSynthesis.config.output_dir = original_output_dir + \"/tuning_parameters/timestep_\" + str(timestep) + \"_resample_\" + str(resample_step)\n",
    "        if trainingSynthesis.accelerator.is_main_process:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "            trainingSynthesis.log_meta_logs()\n",
    "        trainingSynthesis.evaluate(pipeline, deactivate_save_model=True) \n",
    "\n",
    "    # plot lpips score vs  \n",
    "    folder_list = list(Path().glob(original_output_dir + \"/tuning_parameters/timestep_*\"))\n",
    "    lpips = []\n",
    "    labels = [] \n",
    "    for folder in folder_list:\n",
    "        timestep = str(folder).split(\"_\")[-3] \n",
    "        resample_step = str(folder).split(\"_\")[-1]\n",
    "        with open(folder / \"metrics.csv\", 'r') as fp: \n",
    "            _ = fp.readline()\n",
    "            csv_metrics = fp.readline()\n",
    "            reader = csv_metrics.split(',') \n",
    "            for metric in reader:\n",
    "                if metric != \"\":\n",
    "                    name, value = metric.split(':')\n",
    "                    if name == \"lpips\":\n",
    "                        lpips.append(float(value))\n",
    "                        labels.append(timestep + \"_\" + resample_step) \n",
    "    plt.clf()\n",
    "    plt.bar(labels, lpips) \n",
    "    plt.savefig(original_output_dir + '/lpips_parameters.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be170a32-fcb6-41b1-b6ea-14b77eb7b6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook lesion_synthesis_unconditioned.ipynb to script\n",
      "[NbConvertApp] Writing 13943 bytes to lesion_synthesis_unconditioned.py\n"
     ]
    }
   ],
   "source": [
    "#create python script for ubelix \n",
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"lesion_synthesis_unconditioned.ipynb\"\n",
    "filename=\"lesion_synthesis_unconditioned.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
