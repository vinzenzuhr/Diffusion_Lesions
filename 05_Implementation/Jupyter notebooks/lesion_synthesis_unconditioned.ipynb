{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b277e45-ea4c-4639-9398-d22356d0222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, './custom_modules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11f1e0a8-8f60-4b1b-94b8-8367832dccf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### create config\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig: \n",
    "    t1n_target_shape = None # will transform t1n during preprocessing (computationally expensive)\n",
    "    unet_img_shape = (160,256)\n",
    "    channels = 1\n",
    "    train_batch_size = 4 \n",
    "    eval_batch_size = 4  \n",
    "    num_samples_per_batch = 1\n",
    "    num_epochs = 192\n",
    "    gradient_accumulation_steps = 1\n",
    "    learning_rate = 1e-4\n",
    "    lr_warmup_steps = 500\n",
    "    evaluate_epochs = 4 # adjust to num_epochs\n",
    "    evaluate_num_batches = -1 # ~3s/batch. 2.5 min/Evaluation 3D epoch with all batchesr\n",
    "    evaluate_num_batches_3d = -1 \n",
    "    deactivate3Devaluation = False\n",
    "    evaluate_3D_epochs = 1000  # 3 min/Evaluation 3D\n",
    "    save_model_epochs = 100\n",
    "    mixed_precision = \"fp16\"  # `no` for float32, `fp16` for automatic mixed precision\n",
    "    output_dir = \"lesion-synthesis-256-unconditioned\"  # the model name locally and on the HF Hub\n",
    "    dataset_train_path = \"./datasets/synthesis/dataset_train/imgs\"\n",
    "    segm_train_path = \"./datasets/synthesis/dataset_train/segm\"\n",
    "    masks_train_path = \"./datasets/synthesis/dataset_train/masks\"\n",
    "    dataset_eval_path = \"./datasets/synthesis/dataset_eval/imgs\"\n",
    "    segm_eval_path = \"./datasets/synthesis/dataset_eval/segm\"\n",
    "    masks_eval_path = \"./datasets/synthesis/dataset_eval/masks\"\n",
    "    train_only_connected_masks=False  # No Training with lesion masks\n",
    "    eval_only_connected_masks=False \n",
    "    num_inference_steps=50\n",
    "    log_csv = True\n",
    "    add_lesion_technique = \"other_lesions_median\" # 'mean_intensity', 'other_lesions_1stQuantile', 'other_lesions_mean', 'other_lesions_median', or 'other_lesions_3rdQuantile',\n",
    "    intermediate_timestep = 3 # starting from this timesteps. num_inference_steps means the whole pipeline and 1 the last step. \n",
    "    mode = \"train\" # 'train', 'eval' or \"tuning_timestep\"\n",
    "    debug = True \n",
    "    brightness_augmentation = False\n",
    "\n",
    "    push_to_hub = False  # whether to upload the saved model to the HF Hub \n",
    "    seed = 0\n",
    "config = TrainingConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4fc472c2-c374-4859-8ed5-791ebeafbc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.debug:\n",
    "    config.num_inference_steps = 1\n",
    "    config.intermediate_timestep = 1\n",
    "    config.train_batch_size = 1\n",
    "    config.eval_batch_size = 1\n",
    "    config.train_only_connected_masks=False\n",
    "    config.eval_only_connected_masks=False\n",
    "    config.evaluate_num_batches = 3\n",
    "    config.deactivate3Devaluation = False\n",
    "    config.dataset_train_path = \"./datasets/synthesis/dataset_eval/imgs\"\n",
    "    config.segm_train_path = \"./datasets/synthesis/dataset_eval/segm\"\n",
    "    config.masks_train_path = \"./datasets/synthesis/dataset_eval/masks\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "521352b5-cf3f-41a2-b9c3-2fbf8c07c80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration already exists at /home/jovyan/.cache/huggingface/accelerate/default_config.yaml, will not override. Run `accelerate config` manually or pass a different `save_location`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#setup huggingface accelerate\n",
    "import torch\n",
    "import numpy as np\n",
    "import accelerate\n",
    "accelerate.commands.config.default.write_basic_config(config.mixed_precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d2b7df9-0219-4c4e-99f2-08c9b1fc2f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0409a3afb1814bd6977060a66a30ef29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c55bc801af954bd6923992e5c6c2ac8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bee0f4d9a2a543e2a93e9b45389f23f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from DatasetMRI2D import DatasetMRI2D\n",
    "from DatasetMRI3D import DatasetMRI3D\n",
    "from pathlib import Path\n",
    "from torchvision import transforms\n",
    "from transform_utils import ScaleDecorator \n",
    "\n",
    "#add augmentation\n",
    "transformations = None\n",
    "if config.brightness_augmentation:\n",
    "    transformations = transforms.RandomApply([ScaleDecorator(transforms.ColorJitter(brightness=1))], p=0.5)\n",
    "\n",
    "#create dataset\n",
    "datasetTrain = DatasetMRI2D(root_dir_img=Path(config.dataset_train_path), root_dir_segm=Path(config.segm_train_path), only_connected_masks=config.train_only_connected_masks, t1n_target_shape=config.t1n_target_shape, transforms=transformations)\n",
    "datasetEvaluation = DatasetMRI2D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), root_dir_synthesis=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)\n",
    "dataset3DEvaluation = DatasetMRI3D(root_dir_img=Path(config.dataset_eval_path), root_dir_masks=Path(config.masks_eval_path), root_dir_synthesis=Path(config.masks_eval_path), only_connected_masks=config.eval_only_connected_masks, t1n_target_shape=config.t1n_target_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b885175f-4240-49fd-b199-061a3c5ea94e",
   "metadata": {},
   "source": [
    "### Finding good intensity of lesions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a84b00f-2c7b-4583-b9e3-91238db9e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "from tqdm.auto import tqdm\n",
    "from DatasetMRI3D import DatasetMRI3D \n",
    "\n",
    "#skip to speed up\n",
    "if False:\n",
    "    t1w_norm_noskull_list = list(Path(\"temp/unhealthy_DL+DiReCT_Segmentation\").rglob(\"*T1w_norm_noskull.nii.gz\"))\n",
    "    lesion_list = list(Path(\"temp/unhealthy_registered_lesions\").rglob(\"*transformed_lesion.nii.gz\"))\n",
    "    \n",
    "    t1ws = list()\n",
    "    lesions = list()\n",
    "    for i in tqdm(range(len(t1w_norm_noskull_list))):\n",
    "        t1w = nib.load(t1w_norm_noskull_list[i])\n",
    "        t1w = t1w.get_fdata()\n",
    "        t1w, _ = DatasetMRI3D.preprocess(t1w)\n",
    "        lesion = nib.load(lesion_list[i])\n",
    "        lesion = lesion.get_fdata()\n",
    "        lesion = DatasetMRI3D._padding(torch.from_numpy(lesion).to(torch.uint8))\n",
    "        #means.append(t1w[lesion.to(torch.bool)].mean())\n",
    "        #stds.append(t1w[lesion.to(torch.bool)].std())\n",
    "        t1ws.append(t1w)\n",
    "        lesions.append(lesion)\n",
    "    t1w_big = torch.cat(t1ws)\n",
    "    lesion_big = torch.cat(lesions)\n",
    "    \n",
    "    print(\"mean lesion intensity: \", t1w_big[lesion_big.to(torch.bool)].mean()) # -0.3572\n",
    "    print(\"std lesion intensity: \", t1w_big[lesion_big.to(torch.bool)].std()) # 0.1829\n",
    "    print(\"median lesion intensity: \", t1w_big[lesion_big.to(torch.bool)].median()) # 0.1829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46ce44b1-5aa0-4760-b79f-0dab3be0cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import random \n",
    " \n",
    "\n",
    "#skip to speed up\n",
    "if False: \n",
    "    random_idx = torch.randint(len(datasetEvaluation)-1, size=(1,)).item()\n",
    "    \n",
    "    fig, axis = plt.subplots(1,4, figsize=(16,4)) \n",
    "    img = datasetEvaluation[random_idx][\"gt_image\"].squeeze()\n",
    "    img[datasetEvaluation[random_idx][\"mask\"].to(torch.bool).squeeze()] = -0.5492 # mean-std of lesion intensity\n",
    "    axis[0].imshow(datasetEvaluation[random_idx][\"gt_image\"].squeeze()/2+0.5)\n",
    "    axis[0].set_axis_off()\n",
    "    axis[1].imshow(datasetEvaluation[random_idx][\"mask\"].squeeze())\n",
    "    axis[1].set_axis_off()\n",
    "    axis[2].imshow(img/2+0.5)\n",
    "    axis[2].set_axis_off()\n",
    "    axis[3].imshow(datasetEvaluation[random_idx][\"synthesis\"].squeeze())\n",
    "    axis[3].set_axis_off()\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c744a-8c9f-42fb-9342-f7735c5b5032",
   "metadata": {},
   "source": [
    "### Playground LPIPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da88e984-791b-4fc7-8f3a-61ea3dd1d2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip to speed up\n",
    "if False:\n",
    "    from Evaluation2DSynthesis import Evaluation2DSynthesis\n",
    "    from accelerate import Accelerator\n",
    "    from DDIMGuidedPipeline import DDIMGuidedPipeline\n",
    "    \n",
    "    pipeline = DDIMGuidedPipeline.from_pretrained(config.output_dir) \n",
    "    \n",
    "    eval = Evaluation2DSynthesis(config, pipeline, None, None, Accelerator(), None)\n",
    "    images_with_lesions, _ = eval._add_coarse_lesions(datasetEvaluation[123][\"gt_image\"], datasetEvaluation[123])\n",
    "    clean_image=datasetEvaluation[123][\"gt_image\"]\n",
    "    synthesized_images = pipeline(images_with_lesions, 1).images\n",
    "    synthesized_images_2 = pipeline(images_with_lesions, 3).images\n",
    "    print(\"Pips for one timestep: \", eval._calc_lpip(clean_image.unsqueeze(0), synthesized_images))\n",
    "    print(\"Pips for three timestep: \", eval._calc_lpip(clean_image.unsqueeze(0), synthesized_images_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42d4edd7-5123-42f2-8a98-5b4c1c464164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip to speed up\n",
    "if False:\n",
    "    fig, axis = plt.subplots(1,4, figsize=(24,12))\n",
    "    axis[0].imshow(clean_image.squeeze()/2+0.5)\n",
    "    axis[0].set_title(\"original image\")\n",
    "    axis[1].imshow(images_with_lesions.squeeze()/2+0.5)\n",
    "    axis[1].set_title(\"coarse lesions\")\n",
    "    axis[2].imshow(synthesized_images.squeeze()/2+0.5)\n",
    "    axis[2].set_title(\"Diffusion with one timestep\")\n",
    "    axis[3].imshow(synthesized_images_2.squeeze()/2+0.5)\n",
    "    axis[3].set_title(\"Diffusion with three timestep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3a086dd-5273-4c44-aa62-e9cd98a0c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#skip to speed up\n",
    "if False:\n",
    "    diff_1=clean_image-synthesized_images\n",
    "    diff_3=clean_image-synthesized_images_2\n",
    "    fig, axis = plt.subplots(1,2, figsize=(16,8))\n",
    "    axis[0].imshow(diff_1.squeeze()/2+0.5)\n",
    "    axis[0].set_title(\"Differences with one timestep\")\n",
    "    axis[1].imshow(diff_3.squeeze()/2+0.5)\n",
    "    axis[1].set_title(\"Differences with three timestep\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799bdb3-4c83-4ab8-8e46-33d2fe30f49d",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1188218d-a16d-4c0a-896f-e47a140bcdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(\n",
    "    sample_size=config.unet_img_shape,  # the target image resolution\n",
    "    in_channels=config.channels,  # the number of input channels, 3 for RGB images\n",
    "    out_channels=config.channels,  # the number of output channels\n",
    "    layers_per_block=2,  # how many ResNet layers to use per UNet block\n",
    "    block_out_channels=(128, 128, 256, 256, 512, 512),  # the number of output channels for each UNet block\n",
    "    down_block_types=(\n",
    "        \"DownBlock2D\",  # a regular ResNet downsampling block\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"DownBlock2D\",\n",
    "        \"AttnDownBlock2D\",  # a ResNet downsampling block with spatial self-attention\n",
    "        \"DownBlock2D\",\n",
    "    ),\n",
    "    up_block_types=(\n",
    "        \"UpBlock2D\",  # a regular ResNet upsampling block\n",
    "        \"AttnUpBlock2D\",  # a ResNet upsampling block with spatial self-attention\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "        \"UpBlock2D\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "config.model = \"UNet2DModel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4a40c63-4ba1-44aa-8c62-7f15ce816225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup noise scheduler\n",
    "import torch\n",
    "from PIL import Image\n",
    "from diffusers import DDIMScheduler\n",
    "\n",
    "noise_scheduler = DDIMScheduler(num_train_timesteps=1000)\n",
    "\n",
    "config.noise_scheduler = \"DDIMScheduler(num_train_timesteps=1000)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4f42d0a-9ebb-4437-b180-12b79af3c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup lr scheduler\n",
    "from diffusers.optimization import get_cosine_schedule_with_warmup\n",
    "import math\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate)\n",
    "lr_scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=config.lr_warmup_steps,\n",
    "    num_training_steps=(math.ceil(len(datasetTrain)/config.train_batch_size) * config.num_epochs), # num_iterations per epoch * num_epochs\n",
    ")\n",
    "config.lr_scheduler = \"cosine_schedule_with_warmup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2ff284a-4306-4677-829e-98fef153fb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 08:13:22.648794: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 08:13:23.879185: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 08:13:23.879232: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 08:13:23.884482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 08:13:24.410331: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 08:13:24.422662: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 08:13:29.468261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/opt/conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from TrainingUnconditional import TrainingUnconditional\n",
    "from GuidedRePaintPipeline import GuidedRePaintPipeline\n",
    "from Evaluation2DSynthesis import Evaluation2DSynthesis\n",
    "from Evaluation3DSynthesis import Evaluation3DSynthesis \n",
    "import PipelineFactories\n",
    "\n",
    "config.conditional_data = \"None\"\n",
    "\n",
    "args = {\n",
    "    \"config\": config, \n",
    "    \"model\": model, \n",
    "    \"noise_scheduler\": noise_scheduler, \n",
    "    \"optimizer\": optimizer, \n",
    "    \"lr_scheduler\": lr_scheduler, \n",
    "    \"datasetTrain\": datasetTrain, \n",
    "    \"datasetEvaluation\": datasetEvaluation, \n",
    "    \"dataset3DEvaluation\": dataset3DEvaluation, \n",
    "    \"evaluation2D\": Evaluation2DSynthesis,\n",
    "    \"evaluation3D\": Evaluation3DSynthesis, \n",
    "    \"pipelineFactory\": PipelineFactories.get_guided_repaint_pipeline, \n",
    "    \"deactivate3Devaluation\": config.deactivate3Devaluation} \n",
    "trainingSynthesis = TrainingUnconditional(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bac4e0a-2837-4217-a97c-ce940bdc2151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42edec0c277a448da5b20dfaa06b1597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/226 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cfde1123214d7a99e57c94577b751c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "dtype  torch.bool\n",
      "2 masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "2dtype  torch.bool\n",
      "median lesion intensity:  tensor(-0.1110)\n",
      "masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "dtype  torch.bool\n",
      "2 masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "2dtype  torch.bool\n",
      "median lesion intensity:  tensor(0.1018)\n",
      "masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "dtype  torch.bool\n",
      "2 masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "2dtype  torch.bool\n",
      "median lesion intensity:  tensor(-0.1610)\n",
      "ssim_full: 0.9968052506446838\n",
      "ssim_out: 0.9989330768585205\n",
      "ssim_in: 0.7910370826721191\n",
      "mse_full: 8.484104910166934e-05\n",
      "mse_out: nan\n",
      "mse_in: 0.010209808126091957\n",
      "psnr_full: 49.889984130859375\n",
      "psnr_out: nan\n",
      "psnr_in: 26.6533203125\n",
      "val_loss: 0.9099571108818054\n",
      "lpips: 0.0018234249437227845\n",
      "global_step:  1\n",
      "masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "dtype  torch.bool\n",
      "2 masks  tensor([[[[False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          ...,\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False],\n",
      "          [False, False, False,  ..., False, False, False]]]])\n",
      "2dtype  torch.bool\n",
      "median lesion intensity:  tensor(-0.1610)\n",
      "image saved\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a82b29106e024d8eae03a30b07d676f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 3D evaluation\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tensors used as indices must be long, int, byte or bool tensors",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mtrainingSynthesis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/./custom_modules/Training.py:229\u001b[0m, in \u001b[0;36mTraining.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m    227\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/./custom_modules/TrainingUnconditional.py:48\u001b[0m, in \u001b[0;36mTrainingUnconditional.evaluate\u001b[0;34m(self, pipeline)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdeactivate3Devaluation \u001b[38;5;129;01mand\u001b[39;00m ((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mevaluate_3D_epochs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)): \n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation3D(\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig, \n\u001b[1;32m     44\u001b[0m         pipeline, \n\u001b[1;32m     45\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39md3_eval_dataloader, \n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mis_main_process \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb_summary, \n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator)  \n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;43meval\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mglobal_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_pipeline_parameters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Save model\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mis_main_process:\n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/./custom_modules/Evaluation3D.py:48\u001b[0m, in \u001b[0;36mEvaluation3D.evaluate\u001b[0;34m(self, global_step, parameters)\u001b[0m\n\u001b[1;32m     45\u001b[0m name \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m][sample_idx]\n\u001b[1;32m     46\u001b[0m proc_info \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproc_info\u001b[39m\u001b[38;5;124m\"\u001b[39m][sample_idx]\n\u001b[0;32m---> 48\u001b[0m images, clean_images, slice_indices, masks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_start_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#overwrite the original 3D image with the modified 2D slices\u001b[39;00m\n\u001b[1;32m     51\u001b[0m final_3d_images \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mclone(clean_images\u001b[38;5;241m.\u001b[39mdetach()) \n",
      "File \u001b[0;32m~/workdir/Master_Thesis/Diffusion_Lesions/05_Implementation/Jupyter notebooks/./custom_modules/Evaluation3DSynthesis.py:26\u001b[0m, in \u001b[0;36mEvaluation3DSynthesis._start_pipeline\u001b[0;34m(self, batch, sample_idx, parameters)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean lesion intensity: \u001b[39m\u001b[38;5;124m\"\u001b[39m, lesion_intensity)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39madd_lesion_technique \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother_lesions_median\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# use mean of lesion intensity as new lesion intensity\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m     lesion_intensity \u001b[38;5;241m=\u001b[39m \u001b[43mclean_images\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmasks\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mmedian()\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmedian lesion intensity: \u001b[39m\u001b[38;5;124m\"\u001b[39m, lesion_intensity)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39madd_lesion_technique \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mother_lesions_3rdQuantile\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# use 3rd quantile of lesion intensity as new lesion intensity\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tensors used as indices must be long, int, byte or bool tensors"
     ]
    }
   ],
   "source": [
    "if config.mode == \"train\":\n",
    "    trainingSynthesis.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8be7971-c0ac-461d-9fcf-78481e7c9158",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.mode == \"eval\":\n",
    "    pipeline = GuidedRePaintPipeline.from_pretrained(config.output_dir) \n",
    "    trainingSynthesis.evaluate(pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40e6ddc-f89d-451d-9a79-4edc40c05230",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "if config.mode == \"tuning_timestep\":\n",
    "    pipeline = GuidedRePaintPipeline.from_pretrained(config.output_dir)\n",
    "    original_output_dir = config.output_dir \n",
    "    timesteps = [1, 2, 3, 4, 5, 7, 9, 12, 15, 20]\n",
    "    for t in timesteps:\n",
    "        print(\"Begin evaluation for timestep \", t)\n",
    "        trainingSynthesis.config.intermediate_timestep = t\n",
    "        trainingSynthesis.config.output_dir = original_output_dir + \"/tuning_timestep/timestep_\" + str(t)\n",
    "        if trainingSynthesis.accelerator.is_main_process:\n",
    "            os.makedirs(config.output_dir, exist_ok=True)\n",
    "            trainingSynthesis.log_meta_logs()\n",
    "        trainingSynthesis.evaluate(pipeline) \n",
    "\n",
    "    # plot lpips score vs timesteps\n",
    "    original_output_dir = config.output_dir\n",
    "    folder_list = list(Path().glob(\"lesion-synthesis-256-unconditioned_*\"))\n",
    "    lpips_timesteps = []\n",
    "    for folder in folder_list:\n",
    "        timestep = str(folder).split(\"_\")[-1] \n",
    "        with open(folder / \"metrics.csv\", 'r') as fp: \n",
    "            _ = fp.readline()\n",
    "            csv_metrics = fp.readline()  \n",
    "            reader = csv_metrics.split(',')\n",
    "            lpips = None \n",
    "            for metric in reader:  \n",
    "                name, value = metric.split(':')\n",
    "                if name == \"lpips\":\n",
    "                    lpips_timesteps.append((int(timestep), float(value))) \n",
    "    plt.cfg()\n",
    "    for timestep, lpips in lpips_timesteps: \n",
    "        plt.scatter(timestep, lpips)\n",
    "    plt.savefig(config.output_dir + '/lpips_timesteps.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be170a32-fcb6-41b1-b6ea-14b77eb7b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create python script for ubelix \n",
    "import os\n",
    "\n",
    "!jupyter nbconvert --to script \"lesion_synthesis_unconditioned.ipynb\"\n",
    "filename=\"lesion_synthesis_unconditioned.py\"\n",
    "\n",
    "# delete this cell from python file\n",
    "lines = []\n",
    "with open(filename, 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "with open(filename, 'w') as fp:\n",
    "    for number, line in enumerate(lines):\n",
    "        if number < len(lines)-17: \n",
    "            fp.write(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
